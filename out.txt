-- Testing: 216 tests, 16 workers --
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_nested_loop.mlir (1 of 216)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_nested_loop.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --canonicalize --triton-arith-to-linalg --structured-to-memref /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_nested_loop.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_nested_loop.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --canonicalize --triton-arith-to-linalg --structured-to-memref /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_nested_loop.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_nested_loop.mlir
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_nested_loop.mlir:25:16: error: CHECK-SAME: expected string not found in input
// CHECK-SAME: ([[PARAM_0_:%.+]]: memref<*xf32> {tt.divisibility = 16 : i32}, [[PARAM_1_:%.+]]: i32, [[PARAM_2_:%.+]]: i32, [[PARAM_3_:%.+]]: i32, [[PARAM_4_:%.+]]: i32, [[PARAM_5_:%.+]]: i32, [[PARAM_6_:%.+]]: i32) {
               ^
<stdin>:2:32: note: scanning from here
 func.func @reduce_kernel_2d_0d(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32) {
                               ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_nested_loop.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
         1: module { 
         2:  func.func @reduce_kernel_2d_0d(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32) { 
same:25                                    X~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ error: no match found
         3:  %c2_i32 = arith.constant 2 : i32 
same:25     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         4:  %c8_i32 = arith.constant 8 : i32 
same:25     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         5:  %c0_i32 = arith.constant 0 : i32 
same:25     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         6:  %c1_i32 = arith.constant 1 : i32 
same:25     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         7:  %0 = tt.addptr %arg0, %arg4 : !tt.ptr<f32>, i32 
same:25     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         .
         .
         .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_splat_float.mlir (2 of 216)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_splat_float.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :9:9: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
        tt.store %save0, %0 : tensor<1024x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :9:9: note: see current operation: tt.store %arg2, %0 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :9:9: remark: PtrAnalysis: Failed to rewrite StoreOp
        tt.store %save0, %0 : tensor<1024x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :9:9: note: see current operation: tt.store %arg2, %0 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :10:9: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
        tt.store %save1, %1 : tensor<128x256x!tt.ptr<bf16>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :10:9: note: see current operation: tt.store %arg3, %1 : tensor<128x256x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :10:9: remark: PtrAnalysis: Failed to rewrite StoreOp
        tt.store %save1, %1 : tensor<128x256x!tt.ptr<bf16>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :10:9: note: see current operation: tt.store %arg3, %1 : tensor<128x256x!tt.ptr<bf16>>
tensor<1024x!tt.ptr<f32>>
tensor<128x256x!tt.ptr<bf16>>
"builtin.module"() ({
  "tt.func"() <{function_type = (f32, bf16, tensor<1024x!tt.ptr<f32>>, tensor<128x256x!tt.ptr<bf16>>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: f32, %arg1: bf16, %arg2: tensor<1024x!tt.ptr<f32>>, %arg3: tensor<128x256x!tt.ptr<bf16>>):
    %0 = "arith.constant"() <{value = dense<0> : tensor<128x256xi32>}> : () -> tensor<128x256xi32>
    %1 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
    %2 = "tt.splat"(%arg0) : (f32) -> tensor<1024xf32>
    %3 = "tt.splat"(%arg1) : (bf16) -> tensor<128x256xbf16>
    "tt.store"(%1, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
    "tt.store"(%0, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x256xi32>, tensor<128x256xbf16>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
processing val
%1 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
these are the uses:
"tt.store"(%1, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
actual processing
processing user
"tt.store"(%1, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
tensor<1024x!tt.ptr<f32>>
~~~~
processing val
%0 = "arith.constant"() <{value = dense<0> : tensor<128x256xi32>}> : () -> tensor<128x256xi32>
these are the uses:
"tt.store"(%0, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x256xi32>, tensor<128x256xbf16>) -> ()
actual processing
processing user
"tt.store"(%0, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x256xi32>, tensor<128x256xbf16>) -> ()
tensor<128x256x!tt.ptr<bf16>>
~~~~
"builtin.module"() ({
  "tt.func"() <{function_type = (f32, bf16, tensor<1024x!tt.ptr<f32>>, tensor<128x256x!tt.ptr<bf16>>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: f32, %arg1: bf16, %arg2: tensor<1024x!tt.ptr<f32>>, %arg3: tensor<128x256x!tt.ptr<bf16>>):
    %0 = "arith.constant"() <{value = dense<0> : tensor<128x256xi32>}> : () -> tensor<128x256xi32>
    %1 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
    %2 = "tt.splat"(%arg0) : (f32) -> tensor<1024xf32>
    %3 = "tt.splat"(%arg1) : (bf16) -> tensor<128x256xbf16>
    %4 = "tts.create_ptr"(%arg2, %1) : (tensor<1024x!tt.ptr<f32>>, tensor<1024xi32>) -> tensor<1024x!tt.ptr<f32>>
    "tt.store"(%1, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
    %5 = "tts.create_ptr"(%arg3, %0) : (tensor<128x256x!tt.ptr<bf16>>, tensor<128x256xi32>) -> tensor<128x256x!tt.ptr<bf16>>
    "tt.store"(%0, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x256xi32>, tensor<128x256xbf16>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
total addptr count: 0
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:16:16: error: CHECK-SAME: expected string not found in input
// CHECK-SAME: ([[PARAM_0_:%.+]]: f32, [[PARAM_1_:%.+]]: bf16, [[PARAM_2_:%.+]]: tensor<1024x!tt.ptr<f32>>, [[PARAM_3_:%.+]]: tensor<128x256x!tt.ptr<bf16>>, [[PARAM_4_:%.+]]: i32, [[PARAM_5_:%.+]]: i32, [[PARAM_6_:%.+]]: i32, [[PARAM_7_:%.+]]: i32, [[PARAM_8_:%.+]]: i32, [[PARAM_9_:%.+]]: i32) {
               ^
<stdin>:2:19: note: scanning from here
 func.func @kernel(%arg0: f32, %arg1: bf16, %arg2: memref<1024xf32>, %arg3: memref<128x256xbf16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) {
                  ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
         1: module { 
         2:  func.func @kernel(%arg0: f32, %arg1: bf16, %arg2: memref<1024xf32>, %arg3: memref<128x256xbf16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) { 
same:16                       X~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ error: no match found
         3:  %c0 = arith.constant 0 : index 
same:16     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         4:  affine.for %arg10 = 0 to 1024 { 
same:16     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         5:  memref.store %arg0, %arg2[%c0] : memref<1024xf32> 
same:16     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         6:  } 
same:16     ~~~
         7:  %collapse_shape = memref.collapse_shape %arg3 [[0, 1]] : memref<128x256xbf16> into memref<32768xbf16> 
same:16     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         .
         .
         .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_middle_dim.mlir (3 of 216)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_middle_dim.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir:1 offset :37:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %out, %5 : tensor<32x16x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir:1 offset :37:5: note: see current operation: tt.store %arg2, %19 : tensor<32x16x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir:1 offset :37:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %out, %5 : tensor<32x16x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir:1 offset :37:5: note: see current operation: tt.store %arg2, %19 : tensor<32x16x!tt.ptr<bf16>>
tensor<32x16x!tt.ptr<bf16>>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<bf16>, !tt.ptr<bf16>, tensor<32x16x!tt.ptr<bf16>>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>, %arg2: tensor<32x16x!tt.ptr<bf16>>):
    %0 = "arith.constant"() <{value = dense<0> : tensor<32x16xi32>}> : () -> tensor<32x16xi32>
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %3 = "arith.constant"() <{value = 256 : index}> : () -> index
    %4 = "tts.make_tptr"(%arg0, %3) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, order = array<i32>, sizes = array<i64: 32, 256, 16>, static_offsets = array<i64: 0, 0, 0>, static_shape = array<i64: 0, 0, 0>, static_strides = array<i64: -9223372036854775808, 1, 1>}> : (!tt.ptr<bf16>, index) -> tensor<32x256x16x!tt.ptr<bf16>>
    %5 = "tts.load"(%4) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<32x256x16x!tt.ptr<bf16>>) -> tensor<32x256x16xbf16>
    %6 = "tt.reduce"(%5) <{axis = 1 : i32}> ({
    ^bb0(%arg3: bf16, %arg4: bf16):
      %7 = "arith.addf"(%arg3, %arg4) <{fastmath = #arith.fastmath<none>}> : (bf16, bf16) -> bf16
      "tt.reduce.return"(%7) : (bf16) -> ()
    }) : (tensor<32x256x16xbf16>) -> tensor<32x16xbf16>
    "tt.store"(%0, %6) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x16xi32>, tensor<32x16xbf16>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
processing val
%2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
actual processing
~~~~
processing val
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
actual processing
~~~~
processing val
%0 = "arith.constant"() <{value = dense<0> : tensor<32x16xi32>}> : () -> tensor<32x16xi32>
these are the uses:
"tt.store"(%0, %6) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x16xi32>, tensor<32x16xbf16>) -> ()
actual processing
processing user
"tt.store"(%0, %6) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x16xi32>, tensor<32x16xbf16>) -> ()
tensor<32x16x!tt.ptr<bf16>>
~~~~
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<bf16>, !tt.ptr<bf16>, tensor<32x16x!tt.ptr<bf16>>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>, %arg2: tensor<32x16x!tt.ptr<bf16>>):
    %0 = "arith.constant"() <{value = dense<0> : tensor<32x16xi32>}> : () -> tensor<32x16xi32>
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %3 = "arith.constant"() <{value = 256 : index}> : () -> index
    %4 = "tts.make_tptr"(%arg0, %3) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, order = array<i32>, sizes = array<i64: 32, 256, 16>, static_offsets = array<i64: 0, 0, 0>, static_shape = array<i64: 0, 0, 0>, static_strides = array<i64: -9223372036854775808, 1, 1>}> : (!tt.ptr<bf16>, index) -> tensor<32x256x16x!tt.ptr<bf16>>
    %5 = "tts.load"(%4) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<32x256x16x!tt.ptr<bf16>>) -> tensor<32x256x16xbf16>
    %6 = "tt.reduce"(%5) <{axis = 1 : i32}> ({
    ^bb0(%arg3: bf16, %arg4: bf16):
      %8 = "arith.addf"(%arg3, %arg4) <{fastmath = #arith.fastmath<none>}> : (bf16, bf16) -> bf16
      "tt.reduce.return"(%8) : (bf16) -> ()
    }) : (tensor<32x256x16xbf16>) -> tensor<32x16xbf16>
    %7 = "tts.create_ptr"(%arg2, %0) : (tensor<32x16x!tt.ptr<bf16>>, tensor<32x16xi32>) -> tensor<32x16x!tt.ptr<bf16>>
    "tt.store"(%0, %6) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x16xi32>, tensor<32x16xbf16>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
total addptr count: 0
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir:43:16: error: CHECK-SAME: expected string not found in input
// CHECK-SAME: ([[PARAM_0_:%.+]]: memref<*xbf16>, [[PARAM_1_:%.+]]: memref<*xbf16>, [[PARAM_2_:%.+]]: tensor<32x16x!tt.ptr<bf16>>, [[PARAM_3_:%.+]]: i32, [[PARAM_4_:%.+]]: i32, [[PARAM_5_:%.+]]: i32, [[PARAM_6_:%.+]]: i32, [[PARAM_7_:%.+]]: i32, [[PARAM_8_:%.+]]: i32) {
               ^
<stdin>:2:19: note: scanning from here
 func.func @kernel(%arg0: memref<*xbf16>, %arg1: memref<*xbf16>, %arg2: memref<32x16xbf16>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                  ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
         1: module { 
         2:  func.func @kernel(%arg0: memref<*xbf16>, %arg1: memref<*xbf16>, %arg2: memref<32x16xbf16>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) { 
same:43                       X~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ error: no match found
         3:  %c0 = arith.constant 0 : index 
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         4:  %cst = arith.constant 0.000000e+00 : bf16 
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         5:  %c256 = arith.constant 256 : index 
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         6:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [32, 256, 16], strides: [%c256, 1, 1] : memref<*xbf16> to memref<32x256x16xbf16, strided<[?, 1, 1]>> 
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         7:  %alloc = memref.alloc() : memref<32x256x16xbf16> 
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         .
         .
         .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir (4 of 216)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir:1 offset :37:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %res, %6 : tensor<256x16x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir:1 offset :37:5: note: see current operation: tt.store %arg1, %19 : tensor<256x16x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir:1 offset :37:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %res, %6 : tensor<256x16x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir:1 offset :37:5: note: see current operation: tt.store %arg1, %19 : tensor<256x16x!tt.ptr<bf16>>
tensor<256x16x!tt.ptr<bf16>>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<bf16>, tensor<256x16x!tt.ptr<bf16>>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<bf16>, %arg1: tensor<256x16x!tt.ptr<bf16>>):
    %0 = "arith.constant"() <{value = dense<0> : tensor<256x16xi32>}> : () -> tensor<256x16xi32>
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 256 : index}> : () -> index
    %3 = "tts.make_tptr"(%arg0, %2) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, order = array<i32>, sizes = array<i64: 32, 256, 16>, static_offsets = array<i64: 0, 0, 0>, static_shape = array<i64: 0, 0, 0>, static_strides = array<i64: -9223372036854775808, 1, 1>}> : (!tt.ptr<bf16>, index) -> tensor<32x256x16x!tt.ptr<bf16>>
    %4 = "tts.load"(%3) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<32x256x16x!tt.ptr<bf16>>) -> tensor<32x256x16xbf16>
    %5 = "tt.reduce"(%4) <{axis = 0 : i32}> ({
    ^bb0(%arg2: bf16, %arg3: bf16):
      %6 = "arith.cmpf"(%arg2, %arg3) <{fastmath = #arith.fastmath<none>, predicate = 2 : i64}> : (bf16, bf16) -> i1
      %7 = "arith.select"(%6, %arg2, %arg3) : (i1, bf16, bf16) -> bf16
      "tt.reduce.return"(%7) : (bf16) -> ()
    }) : (tensor<32x256x16xbf16>) -> tensor<256x16xbf16>
    "tt.store"(%0, %5) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<256x16xi32>, tensor<256x16xbf16>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
processing val
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
actual processing
~~~~
processing val
%0 = "arith.constant"() <{value = dense<0> : tensor<256x16xi32>}> : () -> tensor<256x16xi32>
these are the uses:
"tt.store"(%0, %5) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<256x16xi32>, tensor<256x16xbf16>) -> ()
actual processing
processing user
"tt.store"(%0, %5) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<256x16xi32>, tensor<256x16xbf16>) -> ()
tensor<256x16x!tt.ptr<bf16>>
~~~~
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<bf16>, tensor<256x16x!tt.ptr<bf16>>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<bf16>, %arg1: tensor<256x16x!tt.ptr<bf16>>):
    %0 = "arith.constant"() <{value = dense<0> : tensor<256x16xi32>}> : () -> tensor<256x16xi32>
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 256 : index}> : () -> index
    %3 = "tts.make_tptr"(%arg0, %2) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, order = array<i32>, sizes = array<i64: 32, 256, 16>, static_offsets = array<i64: 0, 0, 0>, static_shape = array<i64: 0, 0, 0>, static_strides = array<i64: -9223372036854775808, 1, 1>}> : (!tt.ptr<bf16>, index) -> tensor<32x256x16x!tt.ptr<bf16>>
    %4 = "tts.load"(%3) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<32x256x16x!tt.ptr<bf16>>) -> tensor<32x256x16xbf16>
    %5 = "tt.reduce"(%4) <{axis = 0 : i32}> ({
    ^bb0(%arg2: bf16, %arg3: bf16):
      %7 = "arith.cmpf"(%arg2, %arg3) <{fastmath = #arith.fastmath<none>, predicate = 2 : i64}> : (bf16, bf16) -> i1
      %8 = "arith.select"(%7, %arg2, %arg3) : (i1, bf16, bf16) -> bf16
      "tt.reduce.return"(%8) : (bf16) -> ()
    }) : (tensor<32x256x16xbf16>) -> tensor<256x16xbf16>
    %6 = "tts.create_ptr"(%arg1, %0) : (tensor<256x16x!tt.ptr<bf16>>, tensor<256x16xi32>) -> tensor<256x16x!tt.ptr<bf16>>
    "tt.store"(%0, %5) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<256x16xi32>, tensor<256x16xbf16>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
total addptr count: 0
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir:43:16: error: CHECK-SAME: expected string not found in input
// CHECK-SAME: ([[PARAM_0_:%.+]]: memref<*xbf16>, [[PARAM_1_:%.+]]: tensor<256x16x!tt.ptr<bf16>>, [[PARAM_2_:%.+]]: i32, [[PARAM_3_:%.+]]: i32, [[PARAM_4_:%.+]]: i32, [[PARAM_5_:%.+]]: i32, [[PARAM_6_:%.+]]: i32, [[PARAM_7_:%.+]]: i32) {
               ^
<stdin>:2:19: note: scanning from here
 func.func @kernel(%arg0: memref<*xbf16>, %arg1: memref<256x16xbf16>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) {
                  ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
         1: module { 
         2:  func.func @kernel(%arg0: memref<*xbf16>, %arg1: memref<256x16xbf16>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) { 
same:43                       X~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ error: no match found
         3:  %c0 = arith.constant 0 : index 
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         4:  %cst = arith.constant 0xFF80 : bf16 
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         5:  %c256 = arith.constant 256 : index 
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         6:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [32, 256, 16], strides: [%c256, 1, 1] : memref<*xbf16> to memref<32x256x16xbf16, strided<[?, 1, 1]>> 
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         7:  %alloc = memref.alloc() : memref<32x256x16xbf16> 
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         .
         .
         .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir (5 of 216)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir:1 offset :24:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %d, %10 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir:1 offset :24:5: note: see current operation: tt.store %arg3, %13 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir:1 offset :24:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %d, %10 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir:1 offset :24:5: note: see current operation: tt.store %arg3, %13 : tensor<1024x!tt.ptr<f32>>
tensor<1024x!tt.ptr<f32>>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<i1>, !tt.ptr<f32>, !tt.ptr<f32>, tensor<1024x!tt.ptr<f32>>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<i1>, %arg1: !tt.ptr<f32>, %arg2: !tt.ptr<f32>, %arg3: tensor<1024x!tt.ptr<f32>>):
    %0 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %3 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %4 = "tts.make_tptr"(%arg0) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: 0>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<i1>) -> tensor<1024x!tt.ptr<i1>>
    %5 = "tts.make_tptr"(%arg1) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: 0>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>) -> tensor<1024x!tt.ptr<f32>>
    %6 = "tts.make_tptr"(%arg2) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: 0>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>) -> tensor<1024x!tt.ptr<f32>>
    %7 = "tts.load"(%4) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<i1>>) -> tensor<1024xi1>
    %8 = "tts.load"(%5) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %9 = "tts.load"(%6) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %10 = "arith.select"(%7, %8, %9) : (tensor<1024xi1>, tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
    "tt.store"(%0, %10) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
processing val
%3 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
actual processing
~~~~
processing val
%2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
actual processing
~~~~
processing val
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
actual processing
~~~~
processing val
%0 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
these are the uses:
"tt.store"(%0, %10) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
actual processing
processing user
"tt.store"(%0, %10) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
tensor<1024x!tt.ptr<f32>>
~~~~
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<i1>, !tt.ptr<f32>, !tt.ptr<f32>, tensor<1024x!tt.ptr<f32>>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<i1>, %arg1: !tt.ptr<f32>, %arg2: !tt.ptr<f32>, %arg3: tensor<1024x!tt.ptr<f32>>):
    %0 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %3 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %4 = "tts.make_tptr"(%arg0) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: 0>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<i1>) -> tensor<1024x!tt.ptr<i1>>
    %5 = "tts.make_tptr"(%arg1) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: 0>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>) -> tensor<1024x!tt.ptr<f32>>
    %6 = "tts.make_tptr"(%arg2) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: 0>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>) -> tensor<1024x!tt.ptr<f32>>
    %7 = "tts.load"(%4) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<i1>>) -> tensor<1024xi1>
    %8 = "tts.load"(%5) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %9 = "tts.load"(%6) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %10 = "arith.select"(%7, %8, %9) : (tensor<1024xi1>, tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
    %11 = "tts.create_ptr"(%arg3, %0) : (tensor<1024x!tt.ptr<f32>>, tensor<1024xi32>) -> tensor<1024x!tt.ptr<f32>>
    "tt.store"(%0, %10) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
total addptr count: 0
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir:31:16: error: CHECK-SAME: expected string not found in input
// CHECK-SAME: ([[PARAM_0_:%.+]]: memref<*xi1>, [[PARAM_1_:%.+]]: memref<*xf32>, [[PARAM_2_:%.+]]: memref<*xf32>, [[PARAM_3_:%.+]]: tensor<1024x!tt.ptr<f32>>, [[PARAM_4_:%.+]]: i32, [[PARAM_5_:%.+]]: i32, [[PARAM_6_:%.+]]: i32, [[PARAM_7_:%.+]]: i32, [[PARAM_8_:%.+]]: i32, [[PARAM_9_:%.+]]: i32) {
               ^
<stdin>:3:19: note: scanning from here
 func.func @kernel(%arg0: memref<*xi1>, %arg1: memref<*xf32>, %arg2: memref<*xf32>, %arg3: memref<1024xf32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) {
                  ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
         1: #map = affine_map<(d0) -> (d0)> 
         2: module { 
         3:  func.func @kernel(%arg0: memref<*xi1>, %arg1: memref<*xf32>, %arg2: memref<*xf32>, %arg3: memref<1024xf32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) { 
same:31                       X~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ error: no match found
         4:  %c0 = arith.constant 0 : index 
same:31     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         5:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [1024], strides: [1] : memref<*xi1> to memref<1024xi1, strided<[1]>> 
same:31     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         6:  %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [0], sizes: [1024], strides: [1] : memref<*xf32> to memref<1024xf32, strided<[1]>> 
same:31     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         7:  %reinterpret_cast_1 = memref.reinterpret_cast %arg2 to offset: [0], sizes: [1024], strides: [1] : memref<*xf32> to memref<1024xf32, strided<[1]>> 
same:31     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         8:  %alloc = memref.alloc() : memref<1024xi1> 
same:31     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         .
         .
         .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_for.mlir (6 of 216)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_for.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for.mlir
"builtin.module"() ({
  "tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {}], function_type = (!tt.ptr<f32>, !tt.ptr<f32>, i32, i32, i32) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32, %arg4: i32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1024xf32>}> : () -> tensor<1024xf32>
    %3 = "arith.constant"() <{value = 3 : index}> : () -> index
    %4 = "arith.constant"() <{value = 12 : index}> : () -> index
    %5 = "arith.constant"() <{value = 0 : index}> : () -> index
    %6 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
    %7 = "arith.muli"(%6, %arg2) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %8 = "arith.index_cast"(%7) : (i32) -> index
    %9 = "tt.addptr"(%0, %7) : (i32, i32) -> !tt.ptr<f32>
    %10:3 = "scf.for"(%5, %4, %3, %9, %8, %2) ({
    ^bb0(%arg5: index, %arg6: !tt.ptr<f32>, %arg7: index, %arg8: tensor<1024xf32>):
      %14 = "tts.make_tptr"(%arg1, %arg7) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: -9223372036854775808>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>, index) -> tensor<1024x!tt.ptr<f32>>
      %15 = "tts.load"(%14) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
      %16 = "math.exp"(%15) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>) -> tensor<1024xf32>
      %17 = "arith.addf"(%arg8, %16) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
      %18 = "arith.index_cast"(%arg5) : (index) -> i32
      %19 = "arith.addi"(%arg7, %arg5) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %20 = "tt.addptr"(%arg6, %18) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      "scf.yield"(%20, %19, %17) : (!tt.ptr<f32>, index, tensor<1024xf32>) -> ()
    }) : (index, index, index, !tt.ptr<f32>, index, tensor<1024xf32>) -> (!tt.ptr<f32>, index, tensor<1024xf32>)
    %11 = "arith.muli"(%6, %arg3) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %12 = "arith.index_cast"(%11) : (i32) -> index
    %13 = "tts.make_tptr"(%arg0, %12) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: -9223372036854775808>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>, index) -> tensor<1024x!tt.ptr<f32>>
    "tts.store"(%13, %10#2) <{static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>, tensor<1024xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
processing val
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
actual processing
~~~~
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
%9 = "tt.addptr"(%0, %7) : (i32, i32) -> !tt.ptr<f32>
actual processing
processing user
%9 = "tt.addptr"(%0, %7) : (i32, i32) -> !tt.ptr<f32>
~~~~
processing val
%10 = "tt.addptr"(%0, %7) : (i32, i32) -> !tt.ptr<f32>
these are the uses:
%11:3 = "scf.for"(%5, %4, %3, %10, %8, %2) ({
^bb0(%arg5: index, %arg6: !tt.ptr<f32>, %arg7: index, %arg8: tensor<1024xf32>):
  %15 = "tts.make_tptr"(%arg1, %arg7) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: -9223372036854775808>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>, index) -> tensor<1024x!tt.ptr<f32>>
  %16 = "tts.load"(%15) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
  %17 = "math.exp"(%16) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>) -> tensor<1024xf32>
  %18 = "arith.addf"(%arg8, %17) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
  %19 = "arith.index_cast"(%arg5) : (index) -> i32
  %20 = "arith.addi"(%arg7, %arg5) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
  %21 = "tt.addptr"(%arg6, %19) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
  "scf.yield"(%21, %20, %18) : (!tt.ptr<f32>, index, tensor<1024xf32>) -> ()
}) : (index, index, index, !tt.ptr<f32>, index, tensor<1024xf32>) -> (!tt.ptr<f32>, index, tensor<1024xf32>)
actual processing
processing user
%11:3 = "scf.for"(%5, %4, %3, %10, %8, %2) ({
^bb0(%arg5: index, %arg6: !tt.ptr<f32>, %arg7: index, %arg8: tensor<1024xf32>):
  %15 = "tts.make_tptr"(%arg1, %arg7) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: -9223372036854775808>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>, index) -> tensor<1024x!tt.ptr<f32>>
  %16 = "tts.load"(%15) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
  %17 = "math.exp"(%16) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>) -> tensor<1024xf32>
  %18 = "arith.addf"(%arg8, %17) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
  %19 = "arith.index_cast"(%arg5) : (index) -> i32
  %20 = "arith.addi"(%arg7, %arg5) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
  %21 = "tt.addptr"(%arg6, %19) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
  "scf.yield"(%21, %20, %18) : (!tt.ptr<f32>, index, tensor<1024xf32>) -> ()
}) : (index, index, index, !tt.ptr<f32>, index, tensor<1024xf32>) -> (!tt.ptr<f32>, index, tensor<1024xf32>)
arg number: 3
init arg size
3
num region iter-args
3
dump from that index
iter arg
init arg
%10 = "tt.addptr"(%0, %7) : (i32, i32) -> !tt.ptr<f32>
%8 = "arith.index_cast"(%7) : (i32) -> index
%2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1024xf32>}> : () -> tensor<1024xf32>
~~~~
processing val
<block argument> of type 'i32' at index: 1
these are the uses:
%21 = "tt.addptr"(%arg6, %19) : (i32, i32) -> !tt.ptr<f32>
actual processing
processing user
%21 = "tt.addptr"(%arg6, %19) : (i32, i32) -> !tt.ptr<f32>
~~~~
processing val
%11:3 = "scf.for"(%5, %4, %3, %10, %8, %2) ({
^bb0(%arg5: index, %arg6: i32, %arg7: index, %arg8: tensor<1024xf32>):
  %15 = "tts.make_tptr"(%arg1, %arg7) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: -9223372036854775808>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>, index) -> tensor<1024x!tt.ptr<f32>>
  %16 = "tts.load"(%15) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
  %17 = "math.exp"(%16) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>) -> tensor<1024xf32>
  %18 = "arith.addf"(%arg8, %17) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
  %19 = "arith.index_cast"(%arg5) : (index) -> i32
  %20 = "arith.addi"(%arg7, %arg5) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
  %21 = "arith.addi"(%arg6, %19) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.addptr"(%arg6, %19) : (i32, i32) -> !tt.ptr<f32>
  "scf.yield"(%22, %20, %18) : (!tt.ptr<f32>, index, tensor<1024xf32>) -> ()
}) : (index, index, index, !tt.ptr<f32>, index, tensor<1024xf32>) -> (i32, index, tensor<1024xf32>)
these are the uses:
actual processing
~~~~
processing val
%22 = "tt.addptr"(%arg6, %19) : (i32, i32) -> !tt.ptr<f32>
these are the uses:
"scf.yield"(%22, %20, %18) : (!tt.ptr<f32>, index, tensor<1024xf32>) -> ()
actual processing
processing user
"scf.yield"(%22, %20, %18) : (!tt.ptr<f32>, index, tensor<1024xf32>) -> ()
~~~~
"builtin.module"() ({
  "tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {}], function_type = (!tt.ptr<f32>, !tt.ptr<f32>, i32, i32, i32) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32, %arg4: i32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1024xf32>}> : () -> tensor<1024xf32>
    %3 = "arith.constant"() <{value = 3 : index}> : () -> index
    %4 = "arith.constant"() <{value = 12 : index}> : () -> index
    %5 = "arith.constant"() <{value = 0 : index}> : () -> index
    %6 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
    %7 = "arith.muli"(%6, %arg2) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %8 = "arith.index_cast"(%7) : (i32) -> index
    %9 = "arith.addi"(%0, %7) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %10 = "tt.addptr"(%0, %7) : (i32, i32) -> !tt.ptr<f32>
    %11:3 = "scf.for"(%5, %4, %3, %10, %8, %2) ({
    ^bb0(%arg5: index, %arg6: i32, %arg7: index, %arg8: tensor<1024xf32>):
      %15 = "tts.make_tptr"(%arg1, %arg7) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: -9223372036854775808>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>, index) -> tensor<1024x!tt.ptr<f32>>
      %16 = "tts.load"(%15) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
      %17 = "math.exp"(%16) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>) -> tensor<1024xf32>
      %18 = "arith.addf"(%arg8, %17) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
      %19 = "arith.index_cast"(%arg5) : (index) -> i32
      %20 = "arith.addi"(%arg7, %arg5) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %21 = "arith.addi"(%arg6, %19) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
      %22 = "tt.addptr"(%arg6, %19) : (i32, i32) -> !tt.ptr<f32>
      "scf.yield"(%22, %20, %18) : (!tt.ptr<f32>, index, tensor<1024xf32>) -> ()
    }) : (index, index, index, !tt.ptr<f32>, index, tensor<1024xf32>) -> (i32, index, tensor<1024xf32>)
    %12 = "arith.muli"(%6, %arg3) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %13 = "arith.index_cast"(%12) : (i32) -> index
    %14 = "tts.make_tptr"(%arg0, %13) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: -9223372036854775808>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>, index) -> tensor<1024x!tt.ptr<f32>>
    "tts.store"(%14, %11#2) <{static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>, tensor<1024xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
total addptr count: 2
deleting
%10 = "tt.addptr"(%0, %7) : (i32, i32) -> !tt.ptr<f32>
deleting
%22 = "tt.addptr"(%arg6, %19) : (i32, i32) -> !tt.ptr<f32>
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for.mlir:50:11: error: CHECK: expected string not found in input
// CHECK: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_1_]] to offset: {{.}}[[VAR_3_]]{{.}}, sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
          ^
<stdin>:11:41: note: scanning from here
 %3 = arith.index_cast %2 : i32 to index
                                        ^
<stdin>:11:41: note: with "PARAM_1_" equal to "%arg1"
 %3 = arith.index_cast %2 : i32 to index
                                        ^
<stdin>:11:41: note: with "VAR_3_" equal to "%3"
 %3 = arith.index_cast %2 : i32 to index
                                        ^
<stdin>:34:18: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%6], sizes: [1024], strides: [1] : memref<*xf32> to memref<1024xf32, strided<[1], offset: ?>>
                 ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
            .
            .
            .
            6:  %c3 = arith.constant 3 : index 
            7:  %cst = arith.constant 0.000000e+00 : f32 
            8:  %0 = tensor.empty() : tensor<1024xf32> 
            9:  %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1024xf32>) -> tensor<1024xf32> 
           10:  %2 = arith.muli %arg8, %arg2 : i32 
           11:  %3 = arith.index_cast %2 : i32 to index 
check:50'0                                             X error: no match found
check:50'1                                               with "PARAM_1_" equal to "%arg1"
check:50'2                                               with "VAR_3_" equal to "%3"
           12:  %4:3 = scf.for %arg11 = %c0 to %c12 step %c3 iter_args(%arg12 = %2, %arg13 = %3, %arg14 = %1) -> (i32, index, tensor<1024xf32>) { 
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           13:  %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%arg13], sizes: [1024], strides: [1] : memref<*xf32> to memref<1024xf32, strided<[1], offset: ?>> 
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           14:  %alloc = memref.alloc() : memref<1024xf32> 
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           15:  memref.copy %reinterpret_cast_0, %alloc : memref<1024xf32, strided<[1], offset: ?>> to memref<1024xf32> 
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           16:  %7 = bufferization.to_tensor %alloc restrict writable : memref<1024xf32> 
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
            .
            .
            .
           29:  %12 = arith.addi %arg12, %10 : i32 
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           30:  scf.yield %12, %11, %9 : i32, index, tensor<1024xf32> 
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           31:  } 
check:50'0     ~~~
           32:  %5 = arith.muli %arg8, %arg3 : i32 
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           33:  %6 = arith.index_cast %5 : i32 to index 
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           34:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%6], sizes: [1024], strides: [1] : memref<*xf32> to memref<1024xf32, strided<[1], offset: ?>> 
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
check:50'3                      ?                                                                                                                                            possible intended match
           35:  bufferization.materialize_in_destination %4#2 in writable %reinterpret_cast : (tensor<1024xf32>, memref<1024xf32, strided<[1], offset: ?>>) -> () 
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           36:  return 
check:50'0     ~~~~~~~~
           37:  } 
check:50'0     ~~~
           38: } 
check:50'0     ~~
           39:  
check:50'0     ~
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir (7 of 216)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir:1 offset :25:9: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
        tt.store %c, %6 : tensor<1024x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir:1 offset :25:9: note: see current operation: tt.store %arg2, %14 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir:1 offset :25:9: remark: PtrAnalysis: Failed to rewrite StoreOp
        tt.store %c, %6 : tensor<1024x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir:1 offset :25:9: note: see current operation: tt.store %arg2, %14 : tensor<1024x!tt.ptr<f32>>
tensor<1024x!tt.ptr<f32>>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, !tt.ptr<f32>, tensor<1024x!tt.ptr<f32>>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: tensor<1024x!tt.ptr<f32>>):
    %0 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %3 = "tts.make_tptr"(%arg0) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: 0>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>) -> tensor<1024x!tt.ptr<f32>>
    %4 = "tts.make_tptr"(%arg1) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: 0>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>) -> tensor<1024x!tt.ptr<f32>>
    %5 = "tts.load"(%3) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %6 = "tts.load"(%4) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %7 = "arith.addf"(%5, %6) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
    %8 = "arith.subf"(%7, %6) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
    %9 = "arith.mulf"(%8, %6) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
    %10 = "arith.divf"(%9, %6) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
    %11 = "arith.cmpf"(%10, %6) <{fastmath = #arith.fastmath<none>, predicate = 1 : i64}> : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xi1>
    %12 = "arith.select"(%11, %5, %6) : (tensor<1024xi1>, tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
    "tt.store"(%0, %12) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
processing val
%2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
actual processing
~~~~
processing val
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
actual processing
~~~~
processing val
%0 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
these are the uses:
"tt.store"(%0, %12) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
actual processing
processing user
"tt.store"(%0, %12) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
tensor<1024x!tt.ptr<f32>>
~~~~
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, !tt.ptr<f32>, tensor<1024x!tt.ptr<f32>>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: tensor<1024x!tt.ptr<f32>>):
    %0 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %3 = "tts.make_tptr"(%arg0) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: 0>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>) -> tensor<1024x!tt.ptr<f32>>
    %4 = "tts.make_tptr"(%arg1) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: 0>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>) -> tensor<1024x!tt.ptr<f32>>
    %5 = "tts.load"(%3) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %6 = "tts.load"(%4) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %7 = "arith.addf"(%5, %6) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
    %8 = "arith.subf"(%7, %6) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
    %9 = "arith.mulf"(%8, %6) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
    %10 = "arith.divf"(%9, %6) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
    %11 = "arith.cmpf"(%10, %6) <{fastmath = #arith.fastmath<none>, predicate = 1 : i64}> : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xi1>
    %12 = "arith.select"(%11, %5, %6) : (tensor<1024xi1>, tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
    %13 = "tts.create_ptr"(%arg2, %0) : (tensor<1024x!tt.ptr<f32>>, tensor<1024xi32>) -> tensor<1024x!tt.ptr<f32>>
    "tt.store"(%0, %12) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
total addptr count: 0
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir:32:16: error: CHECK-SAME: expected string not found in input
// CHECK-SAME: ([[PARAM_0_:%.+]]: memref<*xf32>, [[PARAM_1_:%.+]]: memref<*xf32>, [[PARAM_2_:%.+]]: tensor<1024x!tt.ptr<f32>>, [[PARAM_3_:%.+]]: i32, [[PARAM_4_:%.+]]: i32, [[PARAM_5_:%.+]]: i32, [[PARAM_6_:%.+]]: i32, [[PARAM_7_:%.+]]: i32, [[PARAM_8_:%.+]]: i32) {
               ^
<stdin>:3:19: note: scanning from here
 func.func @kernel(%arg0: memref<*xf32>, %arg1: memref<*xf32>, %arg2: memref<1024xf32>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                  ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
         1: #map = affine_map<(d0) -> (d0)> 
         2: module { 
         3:  func.func @kernel(%arg0: memref<*xf32>, %arg1: memref<*xf32>, %arg2: memref<1024xf32>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) { 
same:32                       X~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ error: no match found
         4:  %c0 = arith.constant 0 : index 
same:32     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         5:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [1024], strides: [1] : memref<*xf32> to memref<1024xf32, strided<[1]>> 
same:32     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         6:  %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [0], sizes: [1024], strides: [1] : memref<*xf32> to memref<1024xf32, strided<[1]>> 
same:32     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         7:  %alloc = memref.alloc() : memref<1024xf32> 
same:32     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         8:  memref.copy %reinterpret_cast, %alloc : memref<1024xf32, strided<[1]>> to memref<1024xf32> 
same:32     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         .
         .
         .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir (8 of 216)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir:1 offset :30:9: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
        tt.store %d, %100 : tensor<128x128x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir:1 offset :30:9: note: see current operation: tt.store %arg3, %19 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir:1 offset :30:9: remark: PtrAnalysis: Failed to rewrite StoreOp
        tt.store %d, %100 : tensor<128x128x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir:1 offset :30:9: note: see current operation: tt.store %arg3, %19 : tensor<128x128x!tt.ptr<f32>>
tensor<128x128x!tt.ptr<f32>>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<i1>, !tt.ptr<f32>, !tt.ptr<f32>, tensor<128x128x!tt.ptr<f32>>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<i1>, %arg1: !tt.ptr<f32>, %arg2: !tt.ptr<f32>, %arg3: tensor<128x128x!tt.ptr<f32>>):
    %0 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %3 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %4 = "tts.make_tptr"(%arg0) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: 0, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<i1>) -> tensor<128x128x!tt.ptr<i1>>
    %5 = "tts.make_tptr"(%arg1) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: 0, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>) -> tensor<128x128x!tt.ptr<f32>>
    %6 = "tts.make_tptr"(%arg2) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: 0, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>) -> tensor<128x128x!tt.ptr<f32>>
    %7 = "tts.load"(%4) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<i1>>) -> tensor<128x128xi1>
    %8 = "tts.load"(%5) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %9 = "tts.load"(%6) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %10 = "arith.select"(%7, %8, %9) : (tensor<128x128xi1>, tensor<128x128xf32>, tensor<128x128xf32>) -> tensor<128x128xf32>
    "tt.store"(%0, %10) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
processing val
%3 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
actual processing
~~~~
processing val
%2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
actual processing
~~~~
processing val
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
actual processing
~~~~
processing val
%0 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
these are the uses:
"tt.store"(%0, %10) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
actual processing
processing user
"tt.store"(%0, %10) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
tensor<128x128x!tt.ptr<f32>>
~~~~
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<i1>, !tt.ptr<f32>, !tt.ptr<f32>, tensor<128x128x!tt.ptr<f32>>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<i1>, %arg1: !tt.ptr<f32>, %arg2: !tt.ptr<f32>, %arg3: tensor<128x128x!tt.ptr<f32>>):
    %0 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %3 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %4 = "tts.make_tptr"(%arg0) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: 0, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<i1>) -> tensor<128x128x!tt.ptr<i1>>
    %5 = "tts.make_tptr"(%arg1) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: 0, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>) -> tensor<128x128x!tt.ptr<f32>>
    %6 = "tts.make_tptr"(%arg2) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: 0, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>) -> tensor<128x128x!tt.ptr<f32>>
    %7 = "tts.load"(%4) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<i1>>) -> tensor<128x128xi1>
    %8 = "tts.load"(%5) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %9 = "tts.load"(%6) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %10 = "arith.select"(%7, %8, %9) : (tensor<128x128xi1>, tensor<128x128xf32>, tensor<128x128xf32>) -> tensor<128x128xf32>
    %11 = "tts.create_ptr"(%arg3, %0) : (tensor<128x128x!tt.ptr<f32>>, tensor<128x128xi32>) -> tensor<128x128x!tt.ptr<f32>>
    "tt.store"(%0, %10) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
total addptr count: 0
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir:37:16: error: CHECK-SAME: expected string not found in input
// CHECK-SAME: ([[PARAM_0_:%.+]]: memref<*xi1>, [[PARAM_1_:%.+]]: memref<*xf32>, [[PARAM_2_:%.+]]: memref<*xf32>, [[PARAM_3_:%.+]]: tensor<128x128x!tt.ptr<f32>>, [[PARAM_4_:%.+]]: i32, [[PARAM_5_:%.+]]: i32, [[PARAM_6_:%.+]]: i32, [[PARAM_7_:%.+]]: i32, [[PARAM_8_:%.+]]: i32, [[PARAM_9_:%.+]]: i32) {
               ^
<stdin>:3:19: note: scanning from here
 func.func @kernel(%arg0: memref<*xi1>, %arg1: memref<*xf32>, %arg2: memref<*xf32>, %arg3: memref<128x128xf32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) {
                  ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
         1: #map = affine_map<(d0, d1) -> (d0, d1)> 
         2: module { 
         3:  func.func @kernel(%arg0: memref<*xi1>, %arg1: memref<*xf32>, %arg2: memref<*xf32>, %arg3: memref<128x128xf32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) { 
same:37                       X~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ error: no match found
         4:  %c0 = arith.constant 0 : index 
same:37     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         5:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [128, 128], strides: [1, 1] : memref<*xi1> to memref<128x128xi1, strided<[1, 1]>> 
same:37     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         6:  %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [0], sizes: [128, 128], strides: [1, 1] : memref<*xf32> to memref<128x128xf32, strided<[1, 1]>> 
same:37     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         7:  %reinterpret_cast_1 = memref.reinterpret_cast %arg2 to offset: [0], sizes: [128, 128], strides: [1, 1] : memref<*xf32> to memref<128x128xf32, strided<[1, 1]>> 
same:37     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         8:  %alloc = memref.alloc() : memref<128x128xi1> 
same:37     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         .
         .
         .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax.mlir (9 of 216)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental  /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:1 offset :6:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:1 offset :6:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:1 offset :6:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:1 offset :6:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, f32, f32) -> (), sym_name = "minmax_olt", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: f32, %arg2: f32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.cmpf"(%arg1, %arg2) <{fastmath = #arith.fastmath<none>, predicate = 4 : i64}> : (f32, f32) -> i1
    %2 = "arith.select"(%1, %arg1, %arg2) : (i1, f32, f32) -> f32
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
actual processing
processing user
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
!tt.ptr<f32>
~~~~
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, f32, f32) -> (), sym_name = "minmax_olt", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: f32, %arg2: f32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.cmpf"(%arg1, %arg2) <{fastmath = #arith.fastmath<none>, predicate = 4 : i64}> : (f32, f32) -> i1
    %2 = "arith.select"(%1, %arg1, %arg2) : (i1, f32, f32) -> f32
    %3 = "tts.create_ptr"(%arg0, %0) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
total addptr count: 0
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:11 offset :7:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:11 offset :7:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:11 offset :7:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:11 offset :7:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, f32, f32) -> (), sym_name = "minmax_ole", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: f32, %arg2: f32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.cmpf"(%arg1, %arg2) <{fastmath = #arith.fastmath<none>, predicate = 5 : i64}> : (f32, f32) -> i1
    %2 = "arith.select"(%1, %arg1, %arg2) : (i1, f32, f32) -> f32
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
actual processing
processing user
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
!tt.ptr<f32>
~~~~
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, f32, f32) -> (), sym_name = "minmax_ole", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: f32, %arg2: f32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.cmpf"(%arg1, %arg2) <{fastmath = #arith.fastmath<none>, predicate = 5 : i64}> : (f32, f32) -> i1
    %2 = "arith.select"(%1, %arg1, %arg2) : (i1, f32, f32) -> f32
    %3 = "tts.create_ptr"(%arg0, %0) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
total addptr count: 0
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:22 offset :7:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:22 offset :7:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:22 offset :7:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:22 offset :7:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, f32, f32) -> (), sym_name = "minmax_ogt", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: f32, %arg2: f32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.cmpf"(%arg1, %arg2) <{fastmath = #arith.fastmath<none>, predicate = 2 : i64}> : (f32, f32) -> i1
    %2 = "arith.select"(%1, %arg1, %arg2) : (i1, f32, f32) -> f32
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
actual processing
processing user
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
!tt.ptr<f32>
~~~~
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, f32, f32) -> (), sym_name = "minmax_ogt", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: f32, %arg2: f32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.cmpf"(%arg1, %arg2) <{fastmath = #arith.fastmath<none>, predicate = 2 : i64}> : (f32, f32) -> i1
    %2 = "arith.select"(%1, %arg1, %arg2) : (i1, f32, f32) -> f32
    %3 = "tts.create_ptr"(%arg0, %0) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
total addptr count: 0
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:33 offset :7:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:33 offset :7:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:33 offset :7:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:33 offset :7:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, f32, f32) -> (), sym_name = "minmax_oge", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: f32, %arg2: f32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.cmpf"(%arg1, %arg2) <{fastmath = #arith.fastmath<none>, predicate = 3 : i64}> : (f32, f32) -> i1
    %2 = "arith.select"(%1, %arg1, %arg2) : (i1, f32, f32) -> f32
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
actual processing
processing user
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
!tt.ptr<f32>
~~~~
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, f32, f32) -> (), sym_name = "minmax_oge", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: f32, %arg2: f32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.cmpf"(%arg1, %arg2) <{fastmath = #arith.fastmath<none>, predicate = 3 : i64}> : (f32, f32) -> i1
    %2 = "arith.select"(%1, %arg1, %arg2) : (i1, f32, f32) -> f32
    %3 = "tts.create_ptr"(%arg0, %0) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
total addptr count: 0
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:46:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
              ^
<stdin>:2:143: note: scanning from here
 func.func @minmax_olt(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:2:143: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_olt(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:5:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:53:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
              ^
<stdin>:13:143: note: scanning from here
 func.func @minmax_ole(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:13:143: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_ole(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:16:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:60:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
              ^
<stdin>:24:143: note: scanning from here
 func.func @minmax_ogt(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:24:143: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_ogt(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:27:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:67:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
              ^
<stdin>:35:143: note: scanning from here
 func.func @minmax_oge(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:35:143: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_oge(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:38:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
             ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module { 
          2:  func.func @minmax_olt(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) { 
dag:46'0                                                                                                                                                   X error: no match found
dag:46'1                                                                                                                                                     with "PARAM_0_" equal to "%arg0"
          3:  %c0 = arith.constant 0 : index 
dag:46'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %0 = arith.minimumf %arg1, %arg2 : f32 
dag:46'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>> 
dag:46'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:46'2                  ?                                                                                                                                           possible intended match
          6:  affine.store %0, %reinterpret_cast[0] : memref<1xf32, strided<[1], offset: ?>> 
dag:46'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  return 
dag:46'0     ~~~~~~~~
          8:  } 
dag:46'0     ~~~
          9: } 
dag:46'0     ~~
         10:  
dag:46'0     ~
         11: // ----- 
dag:46'0     ~~~~~~~~~
         12: module { 
dag:46'0     ~~~~~~~~~
         13:  func.func @minmax_ole(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) { 
dag:46'0     ~~~~~~~~~~~~~~~~~~~~~~
dag:53'0                                                                                                                                                   X error: no match found
dag:53'1                                                                                                                                                     with "PARAM_0_" equal to "%arg0"
         14:  %c0 = arith.constant 0 : index 
dag:53'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         15:  %0 = arith.minimumf %arg1, %arg2 : f32 
dag:53'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         16:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>> 
dag:53'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:53'2                  ?                                                                                                                                           possible intended match
         17:  affine.store %0, %reinterpret_cast[0] : memref<1xf32, strided<[1], offset: ?>> 
dag:53'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         18:  return 
dag:53'0     ~~~~~~~~
         19:  } 
dag:53'0     ~~~
         20: } 
dag:53'0     ~~
         21:  
dag:53'0     ~
         22: // ----- 
dag:53'0     ~~~~~~~~~
         23: module { 
dag:53'0     ~~~~~~~~~
         24:  func.func @minmax_ogt(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) { 
dag:53'0     ~~~~~~~~~~~~~~~~~~~~~~
dag:60'0                                                                                                                                                   X error: no match found
dag:60'1                                                                                                                                                     with "PARAM_0_" equal to "%arg0"
         25:  %c0 = arith.constant 0 : index 
dag:60'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         26:  %0 = arith.maximumf %arg1, %arg2 : f32 
dag:60'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         27:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>> 
dag:60'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:60'2                  ?                                                                                                                                           possible intended match
         28:  affine.store %0, %reinterpret_cast[0] : memref<1xf32, strided<[1], offset: ?>> 
dag:60'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         29:  return 
dag:60'0     ~~~~~~~~
         30:  } 
dag:60'0     ~~~
         31: } 
dag:60'0     ~~
         32:  
dag:60'0     ~
         33: // ----- 
dag:60'0     ~~~~~~~~~
         34: module { 
dag:60'0     ~~~~~~~~~
         35:  func.func @minmax_oge(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) { 
dag:60'0     ~~~~~~~~~~~~~~~~~~~~~~
dag:67'0                                                                                                                                                   X error: no match found
dag:67'1                                                                                                                                                     with "PARAM_0_" equal to "%arg0"
         36:  %c0 = arith.constant 0 : index 
dag:67'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         37:  %0 = arith.maximumf %arg1, %arg2 : f32 
dag:67'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         38:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>> 
dag:67'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:67'2                  ?                                                                                                                                           possible intended match
         39:  affine.store %0, %reinterpret_cast[0] : memref<1xf32, strided<[1], offset: ?>> 
dag:67'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         40:  return 
dag:67'0     ~~~~~~~~
         41:  } 
dag:67'0     ~~~
         42: } 
dag:67'0     ~~
         43:  
dag:67'0     ~
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir (10 of 216)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir:12:7: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
      tt.store %arg11, %2 : !tt.ptr<f32>
      ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir:12:7: note: see current operation: tt.store %arg11, %3 : !tt.ptr<f32>
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir:12:7: remark: PtrAnalysis: Failed to rewrite StoreOp
      tt.store %arg11, %2 : !tt.ptr<f32>
      ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir:12:7: note: see current operation: tt.store %arg11, %3 : !tt.ptr<f32>
"builtin.module"() ({
  "tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, {}, {}, {}, {}, {}, {}], function_type = (!tt.ptr<f32>, !tt.ptr<f32>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "reduce_kernel_2d_0d1d2de3de"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 1 : i32}> : () -> i32
    %3 = "arith.constant"() <{value = 5 : i32}> : () -> i32
    %4 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %5 = "arith.index_cast"(%arg7) : (i32) -> index
    %6 = "tt.addptr"(%0, %arg7) : (i32, i32) -> !tt.ptr<f32>
    %7 = "arith.sitofp"(%arg7) : (i32) -> f32
    %8:3 = "scf.for"(%4, %3, %2, %6, %5, %5) ({
    ^bb0(%arg10: i32, %arg11: !tt.ptr<f32>, %arg12: index, %arg13: index):
      "tt.store"(%arg11, %7) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<f32>, f32) -> ()
      %9 = "arith.index_cast"(%arg10) : (i32) -> index
      %10 = "arith.addi"(%arg12, %9) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %11 = "tt.addptr"(%arg11, %arg10) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      %12 = "arith.addi"(%arg13, %9) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      "scf.yield"(%11, %10, %12) : (!tt.ptr<f32>, index, index) -> ()
    }) : (i32, i32, i32, !tt.ptr<f32>, index, index) -> (!tt.ptr<f32>, index, index)
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
processing val
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
actual processing
~~~~
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
%6 = "tt.addptr"(%0, %arg7) : (i32, i32) -> !tt.ptr<f32>
actual processing
processing user
%6 = "tt.addptr"(%0, %arg7) : (i32, i32) -> !tt.ptr<f32>
~~~~
processing val
%7 = "tt.addptr"(%0, %arg7) : (i32, i32) -> !tt.ptr<f32>
these are the uses:
%9:3 = "scf.for"(%4, %3, %2, %7, %5, %5) ({
^bb0(%arg10: i32, %arg11: !tt.ptr<f32>, %arg12: index, %arg13: index):
  "tt.store"(%arg11, %8) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<f32>, f32) -> ()
  %10 = "arith.index_cast"(%arg10) : (i32) -> index
  %11 = "arith.addi"(%arg12, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
  %12 = "tt.addptr"(%arg11, %arg10) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
  %13 = "arith.addi"(%arg13, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
  "scf.yield"(%12, %11, %13) : (!tt.ptr<f32>, index, index) -> ()
}) : (i32, i32, i32, !tt.ptr<f32>, index, index) -> (!tt.ptr<f32>, index, index)
actual processing
processing user
%9:3 = "scf.for"(%4, %3, %2, %7, %5, %5) ({
^bb0(%arg10: i32, %arg11: !tt.ptr<f32>, %arg12: index, %arg13: index):
  "tt.store"(%arg11, %8) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<f32>, f32) -> ()
  %10 = "arith.index_cast"(%arg10) : (i32) -> index
  %11 = "arith.addi"(%arg12, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
  %12 = "tt.addptr"(%arg11, %arg10) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
  %13 = "arith.addi"(%arg13, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
  "scf.yield"(%12, %11, %13) : (!tt.ptr<f32>, index, index) -> ()
}) : (i32, i32, i32, !tt.ptr<f32>, index, index) -> (!tt.ptr<f32>, index, index)
arg number: 3
init arg size
3
num region iter-args
3
dump from that index
iter arg
init arg
%7 = "tt.addptr"(%0, %arg7) : (i32, i32) -> !tt.ptr<f32>
%5 = "arith.index_cast"(%arg7) : (i32) -> index
%5 = "arith.index_cast"(%arg7) : (i32) -> index
~~~~
processing val
<block argument> of type 'i32' at index: 1
these are the uses:
"tt.store"(%arg11, %8) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
%12 = "tt.addptr"(%arg11, %arg10) : (i32, i32) -> !tt.ptr<f32>
actual processing
processing user
"tt.store"(%arg11, %8) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
!tt.ptr<f32>
processing user
%13 = "tt.addptr"(%arg11, %arg10) : (i32, i32) -> !tt.ptr<f32>
~~~~
processing val
%9:3 = "scf.for"(%4, %3, %2, %7, %5, %5) ({
^bb0(%arg10: i32, %arg11: i32, %arg12: index, %arg13: index):
  %10 = "tts.create_ptr"(%arg1, %arg11) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
  "tt.store"(%arg11, %8) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
  %11 = "arith.index_cast"(%arg10) : (i32) -> index
  %12 = "arith.addi"(%arg12, %11) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
  %13 = "arith.addi"(%arg11, %arg10) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %14 = "tt.addptr"(%arg11, %arg10) : (i32, i32) -> !tt.ptr<f32>
  %15 = "arith.addi"(%arg13, %11) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
  "scf.yield"(%14, %12, %15) : (!tt.ptr<f32>, index, index) -> ()
}) : (i32, i32, i32, !tt.ptr<f32>, index, index) -> (i32, index, index)
these are the uses:
actual processing
~~~~
processing val
%14 = "tt.addptr"(%arg11, %arg10) : (i32, i32) -> !tt.ptr<f32>
these are the uses:
"scf.yield"(%14, %12, %15) : (!tt.ptr<f32>, index, index) -> ()
actual processing
processing user
"scf.yield"(%14, %12, %15) : (!tt.ptr<f32>, index, index) -> ()
~~~~
"builtin.module"() ({
  "tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, {}, {}, {}, {}, {}, {}], function_type = (!tt.ptr<f32>, !tt.ptr<f32>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "reduce_kernel_2d_0d1d2de3de"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 1 : i32}> : () -> i32
    %3 = "arith.constant"() <{value = 5 : i32}> : () -> i32
    %4 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %5 = "arith.index_cast"(%arg7) : (i32) -> index
    %6 = "arith.addi"(%0, %arg7) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %7 = "tt.addptr"(%0, %arg7) : (i32, i32) -> !tt.ptr<f32>
    %8 = "arith.sitofp"(%arg7) : (i32) -> f32
    %9:3 = "scf.for"(%4, %3, %2, %7, %5, %5) ({
    ^bb0(%arg10: i32, %arg11: i32, %arg12: index, %arg13: index):
      %10 = "tts.create_ptr"(%arg1, %arg11) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      "tt.store"(%arg11, %8) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
      %11 = "arith.index_cast"(%arg10) : (i32) -> index
      %12 = "arith.addi"(%arg12, %11) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %13 = "arith.addi"(%arg11, %arg10) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
      %14 = "tt.addptr"(%arg11, %arg10) : (i32, i32) -> !tt.ptr<f32>
      %15 = "arith.addi"(%arg13, %11) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      "scf.yield"(%14, %12, %15) : (!tt.ptr<f32>, index, index) -> ()
    }) : (i32, i32, i32, !tt.ptr<f32>, index, index) -> (i32, index, index)
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
total addptr count: 2
deleting
%7 = "tt.addptr"(%0, %arg7) : (i32, i32) -> !tt.ptr<f32>
deleting
%14 = "tt.addptr"(%arg11, %arg10) : (i32, i32) -> !tt.ptr<f32>
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir:27:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_0_:%.+]] = arith.index_cast [[PARAM_7_]] : i32 to index
              ^
<stdin>:2:440: note: scanning from here
 func.func @reduce_kernel_2d_0d1d2de3de(%arg0: memref<*xf32> {tt.divisibility = 16 : i32}, %arg1: memref<*xf32> {tt.divisibility = 16 : i32}, %arg2: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32) {
                                                                                                                                                                                                                                                                                                                                                                                                                                                       ^
<stdin>:2:440: note: with "PARAM_7_" equal to "%arg13"
 func.func @reduce_kernel_2d_0d1d2de3de(%arg0: memref<*xf32> {tt.divisibility = 16 : i32}, %arg1: memref<*xf32> {tt.divisibility = 16 : i32}, %arg2: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32) {
                                                                                                                                                                                                                                                                                                                                                                                                                                                       ^
<stdin>:6:2: note: possible intended match here
 %0 = arith.index_cast %arg7 : i32 to index
 ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module { 
          2:  func.func @reduce_kernel_2d_0d1d2de3de(%arg0: memref<*xf32> {tt.divisibility = 16 : i32}, %arg1: memref<*xf32> {tt.divisibility = 16 : i32}, %arg2: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32) { 
dag:27'0                                                                                                                                                                                                                                                                                                                                                                                                                                                            X error: no match found
dag:27'1                                                                                                                                                                                                                                                                                                                                                                                                                                                              with "PARAM_7_" equal to "%arg13"
          3:  %c0_i32 = arith.constant 0 : i32 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %c1_i32 = arith.constant 1 : i32 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %c5_i32 = arith.constant 5 : i32 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          6:  %0 = arith.index_cast %arg7 : i32 to index 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:27'2      ?                                           possible intended match
          7:  %1 = arith.sitofp %arg7 : i32 to f32 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          8:  %2:3 = scf.for %arg16 = %c0_i32 to %c5_i32 step %c1_i32 iter_args(%arg17 = %arg7, %arg18 = %0, %arg19 = %0) -> (i32, index, index) : i32 { 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          9:  %3 = arith.index_cast %arg17 : i32 to index 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         10:  %reinterpret_cast = memref.reinterpret_cast %arg1 to offset: [%3], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>> 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         11:  affine.store %1, %reinterpret_cast[0] : memref<1xf32, strided<[1], offset: ?>> 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          .
          .
          .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir (11 of 216)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir
"builtin.module"() ({
  "tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {}], function_type = (!tt.ptr<f32>, !tt.ptr<f32>, i32, i32, i32) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32, %arg4: i32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 128 : index}> : () -> index
    %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<128x128xf32>}> : () -> tensor<128x128xf32>
    %4 = "arith.constant"() <{value = 3 : index}> : () -> index
    %5 = "arith.constant"() <{value = 12 : index}> : () -> index
    %6 = "arith.constant"() <{value = 0 : index}> : () -> index
    %7 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
    %8 = "arith.muli"(%7, %arg2) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %9 = "arith.index_cast"(%8) : (i32) -> index
    %10 = "tt.addptr"(%0, %8) : (i32, i32) -> !tt.ptr<f32>
    %11:3 = "scf.for"(%6, %5, %4, %3, %10, %9) ({
    ^bb0(%arg5: index, %arg6: tensor<128x128xf32>, %arg7: !tt.ptr<f32>, %arg8: index):
      %16 = "arith.addi"(%arg8, %2) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %17 = "tts.make_tptr"(%arg1, %16) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: -9223372036854775808, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>, index) -> tensor<128x128x!tt.ptr<f32>>
      %18 = "tts.load"(%17) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
      %19 = "math.exp"(%18) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>) -> tensor<128x128xf32>
      %20 = "arith.addf"(%arg6, %19) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>, tensor<128x128xf32>) -> tensor<128x128xf32>
      %21 = "arith.index_cast"(%arg5) : (index) -> i32
      %22 = "arith.addi"(%arg8, %arg5) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %23 = "tt.addptr"(%arg7, %21) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      "scf.yield"(%20, %23, %22) : (tensor<128x128xf32>, !tt.ptr<f32>, index) -> ()
    }) : (index, index, index, tensor<128x128xf32>, !tt.ptr<f32>, index) -> (tensor<128x128xf32>, !tt.ptr<f32>, index)
    %12 = "arith.muli"(%7, %arg3) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %13 = "arith.index_cast"(%12) : (i32) -> index
    %14 = "arith.addi"(%13, %2) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
    %15 = "tts.make_tptr"(%arg0, %14) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: -9223372036854775808, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>, index) -> tensor<128x128x!tt.ptr<f32>>
    "tts.store"(%15, %11#0) <{static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>, tensor<128x128xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
processing val
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
actual processing
~~~~
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
%10 = "tt.addptr"(%0, %8) : (i32, i32) -> !tt.ptr<f32>
actual processing
processing user
%10 = "tt.addptr"(%0, %8) : (i32, i32) -> !tt.ptr<f32>
~~~~
processing val
%11 = "tt.addptr"(%0, %8) : (i32, i32) -> !tt.ptr<f32>
these are the uses:
%12:3 = "scf.for"(%6, %5, %4, %3, %11, %9) ({
^bb0(%arg5: index, %arg6: tensor<128x128xf32>, %arg7: !tt.ptr<f32>, %arg8: index):
  %17 = "arith.addi"(%arg8, %2) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
  %18 = "tts.make_tptr"(%arg1, %17) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: -9223372036854775808, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>, index) -> tensor<128x128x!tt.ptr<f32>>
  %19 = "tts.load"(%18) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
  %20 = "math.exp"(%19) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>) -> tensor<128x128xf32>
  %21 = "arith.addf"(%arg6, %20) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>, tensor<128x128xf32>) -> tensor<128x128xf32>
  %22 = "arith.index_cast"(%arg5) : (index) -> i32
  %23 = "arith.addi"(%arg8, %arg5) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
  %24 = "tt.addptr"(%arg7, %22) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
  "scf.yield"(%21, %24, %23) : (tensor<128x128xf32>, !tt.ptr<f32>, index) -> ()
}) : (index, index, index, tensor<128x128xf32>, !tt.ptr<f32>, index) -> (tensor<128x128xf32>, !tt.ptr<f32>, index)
actual processing
processing user
%12:3 = "scf.for"(%6, %5, %4, %3, %11, %9) ({
^bb0(%arg5: index, %arg6: tensor<128x128xf32>, %arg7: !tt.ptr<f32>, %arg8: index):
  %17 = "arith.addi"(%arg8, %2) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
  %18 = "tts.make_tptr"(%arg1, %17) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: -9223372036854775808, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>, index) -> tensor<128x128x!tt.ptr<f32>>
  %19 = "tts.load"(%18) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
  %20 = "math.exp"(%19) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>) -> tensor<128x128xf32>
  %21 = "arith.addf"(%arg6, %20) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>, tensor<128x128xf32>) -> tensor<128x128xf32>
  %22 = "arith.index_cast"(%arg5) : (index) -> i32
  %23 = "arith.addi"(%arg8, %arg5) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
  %24 = "tt.addptr"(%arg7, %22) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
  "scf.yield"(%21, %24, %23) : (tensor<128x128xf32>, !tt.ptr<f32>, index) -> ()
}) : (index, index, index, tensor<128x128xf32>, !tt.ptr<f32>, index) -> (tensor<128x128xf32>, !tt.ptr<f32>, index)
arg number: 4
init arg size
3
num region iter-args
3
dump from that index
iter arg
init arg
%3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<128x128xf32>}> : () -> tensor<128x128xf32>
%11 = "tt.addptr"(%0, %8) : (i32, i32) -> !tt.ptr<f32>
%9 = "arith.index_cast"(%8) : (i32) -> index
~~~~
processing val
<block argument> of type 'i32' at index: 2
these are the uses:
%24 = "tt.addptr"(%arg7, %22) : (i32, i32) -> !tt.ptr<f32>
actual processing
processing user
%24 = "tt.addptr"(%arg7, %22) : (i32, i32) -> !tt.ptr<f32>
~~~~
processing val
%12:3 = "scf.for"(%6, %5, %4, %3, %11, %9) ({
^bb0(%arg5: index, %arg6: tensor<128x128xf32>, %arg7: i32, %arg8: index):
  %17 = "arith.addi"(%arg8, %2) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
  %18 = "tts.make_tptr"(%arg1, %17) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: -9223372036854775808, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>, index) -> tensor<128x128x!tt.ptr<f32>>
  %19 = "tts.load"(%18) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
  %20 = "math.exp"(%19) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>) -> tensor<128x128xf32>
  %21 = "arith.addf"(%arg6, %20) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>, tensor<128x128xf32>) -> tensor<128x128xf32>
  %22 = "arith.index_cast"(%arg5) : (index) -> i32
  %23 = "arith.addi"(%arg8, %arg5) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
  %24 = "arith.addi"(%arg7, %22) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %25 = "tt.addptr"(%arg7, %22) : (i32, i32) -> !tt.ptr<f32>
  "scf.yield"(%21, %25, %23) : (tensor<128x128xf32>, !tt.ptr<f32>, index) -> ()
}) : (index, index, index, tensor<128x128xf32>, !tt.ptr<f32>, index) -> (tensor<128x128xf32>, i32, index)
these are the uses:
actual processing
~~~~
processing val
%25 = "tt.addptr"(%arg7, %22) : (i32, i32) -> !tt.ptr<f32>
these are the uses:
"scf.yield"(%21, %25, %23) : (tensor<128x128xf32>, !tt.ptr<f32>, index) -> ()
actual processing
processing user
"scf.yield"(%21, %25, %23) : (tensor<128x128xf32>, !tt.ptr<f32>, index) -> ()
~~~~
"builtin.module"() ({
  "tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {}], function_type = (!tt.ptr<f32>, !tt.ptr<f32>, i32, i32, i32) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32, %arg4: i32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 128 : index}> : () -> index
    %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<128x128xf32>}> : () -> tensor<128x128xf32>
    %4 = "arith.constant"() <{value = 3 : index}> : () -> index
    %5 = "arith.constant"() <{value = 12 : index}> : () -> index
    %6 = "arith.constant"() <{value = 0 : index}> : () -> index
    %7 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
    %8 = "arith.muli"(%7, %arg2) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %9 = "arith.index_cast"(%8) : (i32) -> index
    %10 = "arith.addi"(%0, %8) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %11 = "tt.addptr"(%0, %8) : (i32, i32) -> !tt.ptr<f32>
    %12:3 = "scf.for"(%6, %5, %4, %3, %11, %9) ({
    ^bb0(%arg5: index, %arg6: tensor<128x128xf32>, %arg7: i32, %arg8: index):
      %17 = "arith.addi"(%arg8, %2) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %18 = "tts.make_tptr"(%arg1, %17) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: -9223372036854775808, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>, index) -> tensor<128x128x!tt.ptr<f32>>
      %19 = "tts.load"(%18) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
      %20 = "math.exp"(%19) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>) -> tensor<128x128xf32>
      %21 = "arith.addf"(%arg6, %20) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>, tensor<128x128xf32>) -> tensor<128x128xf32>
      %22 = "arith.index_cast"(%arg5) : (index) -> i32
      %23 = "arith.addi"(%arg8, %arg5) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %24 = "arith.addi"(%arg7, %22) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
      %25 = "tt.addptr"(%arg7, %22) : (i32, i32) -> !tt.ptr<f32>
      "scf.yield"(%21, %25, %23) : (tensor<128x128xf32>, !tt.ptr<f32>, index) -> ()
    }) : (index, index, index, tensor<128x128xf32>, !tt.ptr<f32>, index) -> (tensor<128x128xf32>, i32, index)
    %13 = "arith.muli"(%7, %arg3) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %14 = "arith.index_cast"(%13) : (i32) -> index
    %15 = "arith.addi"(%14, %2) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
    %16 = "tts.make_tptr"(%arg0, %15) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: -9223372036854775808, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>, index) -> tensor<128x128x!tt.ptr<f32>>
    "tts.store"(%16, %12#0) <{static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>, tensor<128x128xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
total addptr count: 2
deleting
%25 = "tt.addptr"(%arg7, %22) : (i32, i32) -> !tt.ptr<f32>
deleting
%11 = "tt.addptr"(%0, %8) : (i32, i32) -> !tt.ptr<f32>
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir:70:11: error: CHECK: expected string not found in input
// CHECK: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_1_]] to offset: {{.}}[[VAR_3_]]{{.}}, sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
          ^
<stdin>:12:41: note: scanning from here
 %3 = arith.index_cast %2 : i32 to index
                                        ^
<stdin>:12:41: note: with "PARAM_1_" equal to "%arg1"
 %3 = arith.index_cast %2 : i32 to index
                                        ^
<stdin>:12:41: note: with "VAR_3_" equal to "%3"
 %3 = arith.index_cast %2 : i32 to index
                                        ^
<stdin>:15:18: note: possible intended match here
 %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%8], sizes: [128, 128], strides: [1, 1] : memref<*xf32> to memref<128x128xf32, strided<[1, 1], offset: ?>>
                 ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
            .
            .
            .
            7:  %c128 = arith.constant 128 : index 
            8:  %cst = arith.constant 0.000000e+00 : f32 
            9:  %0 = tensor.empty() : tensor<128x128xf32> 
           10:  %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<128x128xf32>) -> tensor<128x128xf32> 
           11:  %2 = arith.muli %arg8, %arg2 : i32 
           12:  %3 = arith.index_cast %2 : i32 to index 
check:70'0                                             X error: no match found
check:70'1                                               with "PARAM_1_" equal to "%arg1"
check:70'2                                               with "VAR_3_" equal to "%3"
           13:  %4:3 = scf.for %arg11 = %c0 to %c12 step %c3 iter_args(%arg12 = %1, %arg13 = %2, %arg14 = %3) -> (tensor<128x128xf32>, i32, index) { 
check:70'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           14:  %8 = arith.addi %arg14, %c128 : index 
check:70'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           15:  %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%8], sizes: [128, 128], strides: [1, 1] : memref<*xf32> to memref<128x128xf32, strided<[1, 1], offset: ?>> 
check:70'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
check:70'3                      ?                                                                                                                                                           possible intended match
           16:  %alloc = memref.alloc() : memref<128x128xf32> 
check:70'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           17:  memref.copy %reinterpret_cast_0, %alloc : memref<128x128xf32, strided<[1, 1], offset: ?>> to memref<128x128xf32> 
check:70'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           18:  %9 = bufferization.to_tensor %alloc restrict writable : memref<128x128xf32> 
check:70'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           19:  %10 = linalg.generic {indexing_maps = [#map, #map], iterator_types = ["parallel", "parallel"]} ins(%9 : tensor<128x128xf32>) outs(%9 : tensor<128x128xf32>) { 
check:70'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           20:  ^bb0(%in: f32, %out: f32): 
check:70'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
            .
            .
            .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir (12 of 216)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :27:9: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
        tt.store %c, %res0 : tensor<128x128x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :27:9: note: see current operation: tt.store %arg2, %15 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :27:9: remark: PtrAnalysis: Failed to rewrite StoreOp
        tt.store %c, %res0 : tensor<128x128x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :27:9: note: see current operation: tt.store %arg2, %15 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :28:9: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
        tt.store %d, %res1 : tensor<128x128x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :28:9: note: see current operation: tt.store %arg3, %16 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :28:9: remark: PtrAnalysis: Failed to rewrite StoreOp
        tt.store %d, %res1 : tensor<128x128x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :28:9: note: see current operation: tt.store %arg3, %16 : tensor<128x128x!tt.ptr<f32>>
tensor<128x128x!tt.ptr<f32>>
tensor<128x128x!tt.ptr<f32>>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, !tt.ptr<f32>, tensor<128x128x!tt.ptr<f32>>, tensor<128x128x!tt.ptr<f32>>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: tensor<128x128x!tt.ptr<f32>>, %arg3: tensor<128x128x!tt.ptr<f32>>):
    %0 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
    %1 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
    %2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %3 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %4 = "tts.make_tptr"(%arg0) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: 0, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>) -> tensor<128x128x!tt.ptr<f32>>
    %5 = "tts.make_tptr"(%arg1) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: 0, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>) -> tensor<128x128x!tt.ptr<f32>>
    %6 = "tts.load"(%4) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %7 = "tts.load"(%5) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %8 = "arith.addf"(%6, %7) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>, tensor<128x128xf32>) -> tensor<128x128xf32>
    %9 = "arith.subf"(%6, %7) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>, tensor<128x128xf32>) -> tensor<128x128xf32>
    "tt.store"(%1, %8) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
    "tt.store"(%0, %9) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
processing val
%3 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
actual processing
~~~~
processing val
%2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
actual processing
~~~~
processing val
%1 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
these are the uses:
"tt.store"(%1, %8) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
actual processing
processing user
"tt.store"(%1, %8) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
tensor<128x128x!tt.ptr<f32>>
~~~~
processing val
%0 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
these are the uses:
"tt.store"(%0, %9) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
actual processing
processing user
"tt.store"(%0, %9) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
tensor<128x128x!tt.ptr<f32>>
~~~~
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, !tt.ptr<f32>, tensor<128x128x!tt.ptr<f32>>, tensor<128x128x!tt.ptr<f32>>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: tensor<128x128x!tt.ptr<f32>>, %arg3: tensor<128x128x!tt.ptr<f32>>):
    %0 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
    %1 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
    %2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %3 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %4 = "tts.make_tptr"(%arg0) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: 0, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>) -> tensor<128x128x!tt.ptr<f32>>
    %5 = "tts.make_tptr"(%arg1) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: 0, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>) -> tensor<128x128x!tt.ptr<f32>>
    %6 = "tts.load"(%4) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %7 = "tts.load"(%5) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %8 = "arith.addf"(%6, %7) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>, tensor<128x128xf32>) -> tensor<128x128xf32>
    %9 = "arith.subf"(%6, %7) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>, tensor<128x128xf32>) -> tensor<128x128xf32>
    %10 = "tts.create_ptr"(%arg2, %1) : (tensor<128x128x!tt.ptr<f32>>, tensor<128x128xi32>) -> tensor<128x128x!tt.ptr<f32>>
    "tt.store"(%1, %8) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
    %11 = "tts.create_ptr"(%arg3, %0) : (tensor<128x128x!tt.ptr<f32>>, tensor<128x128xi32>) -> tensor<128x128x!tt.ptr<f32>>
    "tt.store"(%0, %9) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
total addptr count: 0
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:35:16: error: CHECK-SAME: expected string not found in input
// CHECK-SAME: ([[PARAM_0_:%.+]]: memref<*xf32>, [[PARAM_1_:%.+]]: memref<*xf32>, [[PARAM_2_:%.+]]: tensor<128x128x!tt.ptr<f32>>, [[PARAM_3_:%.+]]: tensor<128x128x!tt.ptr<f32>>, [[PARAM_4_:%.+]]: i32, [[PARAM_5_:%.+]]: i32, [[PARAM_6_:%.+]]: i32, [[PARAM_7_:%.+]]: i32, [[PARAM_8_:%.+]]: i32, [[PARAM_9_:%.+]]: i32) {
               ^
<stdin>:3:19: note: scanning from here
 func.func @kernel(%arg0: memref<*xf32>, %arg1: memref<*xf32>, %arg2: memref<128x128xf32>, %arg3: memref<128x128xf32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) {
                  ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
         1: #map = affine_map<(d0, d1) -> (d0, d1)> 
         2: module { 
         3:  func.func @kernel(%arg0: memref<*xf32>, %arg1: memref<*xf32>, %arg2: memref<128x128xf32>, %arg3: memref<128x128xf32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) { 
same:35                       X~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ error: no match found
         4:  %c0 = arith.constant 0 : index 
same:35     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         5:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [128, 128], strides: [1, 1] : memref<*xf32> to memref<128x128xf32, strided<[1, 1]>> 
same:35     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         6:  %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [0], sizes: [128, 128], strides: [1, 1] : memref<*xf32> to memref<128x128xf32, strided<[1, 1]>> 
same:35     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         7:  %alloc = memref.alloc() : memref<128x128xf32> 
same:35     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         8:  memref.copy %reinterpret_cast, %alloc : memref<128x128xf32, strided<[1, 1]>> to memref<128x128xf32> 
same:35     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         .
         .
         .
>>>>>>

--

********************
UNRESOLVED: TRITON-SHARED :: Conversion/fail.mlir (13 of 216)
******************** TEST 'TRITON-SHARED :: Conversion/fail.mlir' FAILED ********************
Test has no 'RUN:' line
********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir (14 of 216)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental  /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:1 offset :11:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:1 offset :11:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:1 offset :11:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:1 offset :11:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<f32>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>) -> (), sym_name = "maxnumf", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<f32>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<4096xf32>}> : () -> tensor<4096xf32>
    %2 = "tt.reduce"(%1) <{axis = 0 : i32}> ({
    ^bb0(%arg1: f32, %arg2: f32):
      %3 = "arith.maxnumf"(%arg1, %arg2) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
      "tt.reduce.return"(%3) : (f32) -> ()
    }) : (tensor<4096xf32>) -> f32
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
actual processing
processing user
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
!tt.ptr<f32>
~~~~
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>) -> (), sym_name = "maxnumf", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<f32>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<4096xf32>}> : () -> tensor<4096xf32>
    %2 = "tt.reduce"(%1) <{axis = 0 : i32}> ({
    ^bb0(%arg1: f32, %arg2: f32):
      %4 = "arith.maxnumf"(%arg1, %arg2) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
      "tt.reduce.return"(%4) : (f32) -> ()
    }) : (tensor<4096xf32>) -> f32
    %3 = "tts.create_ptr"(%arg0, %0) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
total addptr count: 0
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:37 offset :12:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:37 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:37 offset :12:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:37 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<f32>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>) -> (), sym_name = "minnumf", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<f32>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<4096xf32>}> : () -> tensor<4096xf32>
    %2 = "tt.reduce"(%1) <{axis = 0 : i32}> ({
    ^bb0(%arg1: f32, %arg2: f32):
      %3 = "arith.minnumf"(%arg1, %arg2) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
      "tt.reduce.return"(%3) : (f32) -> ()
    }) : (tensor<4096xf32>) -> f32
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
actual processing
processing user
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
!tt.ptr<f32>
~~~~
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>) -> (), sym_name = "minnumf", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<f32>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<4096xf32>}> : () -> tensor<4096xf32>
    %2 = "tt.reduce"(%1) <{axis = 0 : i32}> ({
    ^bb0(%arg1: f32, %arg2: f32):
      %4 = "arith.minnumf"(%arg1, %arg2) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
      "tt.reduce.return"(%4) : (f32) -> ()
    }) : (tensor<4096xf32>) -> f32
    %3 = "tts.create_ptr"(%arg0, %0) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
total addptr count: 0
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:20:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
              ^
<stdin>:2:116: note: scanning from here
 func.func @maxnumf(%arg0: memref<*xf32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                   ^
<stdin>:2:116: note: with "PARAM_0_" equal to "%arg0"
 func.func @maxnumf(%arg0: memref<*xf32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                   ^
<stdin>:16:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:57:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
              ^
<stdin>:24:116: note: scanning from here
 func.func @minnumf(%arg0: memref<*xf32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                   ^
<stdin>:24:116: note: with "PARAM_0_" equal to "%arg0"
 func.func @minnumf(%arg0: memref<*xf32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                   ^
<stdin>:38:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
             ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module { 
          2:  func.func @maxnumf(%arg0: memref<*xf32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) { 
dag:20'0                                                                                                                        X error: no match found
dag:20'1                                                                                                                          with "PARAM_0_" equal to "%arg0"
          3:  %c0 = arith.constant 0 : index 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %cst = arith.constant 0xFF800000 : f32 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %cst_0 = arith.constant 0.000000e+00 : f32 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          6:  %0 = tensor.empty() : tensor<4096xf32> 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  %1 = linalg.fill ins(%cst_0 : f32) outs(%0 : tensor<4096xf32>) -> tensor<4096xf32> 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          .
          .
          .
         11:  (%in: f32, %init: f32) { 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~
         12:  %3 = arith.maxnumf %in, %init : f32 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         13:  linalg.yield %3 : f32 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~
         14:  } 
dag:20'0     ~~~
         15:  %extracted = tensor.extract %reduced[] : tensor<f32> 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         16:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>> 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:20'2                  ?                                                                                                                                           possible intended match
         17:  affine.store %extracted, %reinterpret_cast[0] : memref<1xf32, strided<[1], offset: ?>> 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         18:  return 
dag:20'0     ~~~~~~~~
         19:  } 
dag:20'0     ~~~
         20: } 
dag:20'0     ~~
         21:  
dag:20'0     ~
         22: // ----- 
dag:20'0     ~~~~~~~~~
         23: module { 
dag:20'0     ~~~~~~~~~
         24:  func.func @minnumf(%arg0: memref<*xf32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) { 
dag:20'0     ~~~~~~~~~~~~~~~~~~~
dag:57'0                                                                                                                        X error: no match found
dag:57'1                                                                                                                          with "PARAM_0_" equal to "%arg0"
         25:  %c0 = arith.constant 0 : index 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         26:  %cst = arith.constant 0x7F800000 : f32 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         27:  %cst_0 = arith.constant 0.000000e+00 : f32 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         28:  %0 = tensor.empty() : tensor<4096xf32> 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         29:  %1 = linalg.fill ins(%cst_0 : f32) outs(%0 : tensor<4096xf32>) -> tensor<4096xf32> 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          .
          .
          .
         33:  (%in: f32, %init: f32) { 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~
         34:  %3 = arith.minnumf %in, %init : f32 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         35:  linalg.yield %3 : f32 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~
         36:  } 
dag:57'0     ~~~
         37:  %extracted = tensor.extract %reduced[] : tensor<f32> 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         38:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>> 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:57'2                  ?                                                                                                                                           possible intended match
         39:  affine.store %extracted, %reinterpret_cast[0] : memref<1xf32, strided<[1], offset: ?>> 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         40:  return 
dag:57'0     ~~~~~~~~
         41:  } 
dag:57'0     ~~~
         42: } 
dag:57'0     ~~
         43:  
dag:57'0     ~
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir (15 of 216)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --canonicalize --triton-arith-to-linalg --structured-to-memref /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --canonicalize --triton-arith-to-linalg --structured-to-memref /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir:19:16: error: CHECK-SAME: expected string not found in input
// CHECK-SAME: ([[PARAM_0_:%.+]]: memref<*xf32> {tt.divisibility = 16 : i32}, [[PARAM_1_:%.+]]: memref<*xf32> {tt.divisibility = 16 : i32}, [[PARAM_2_:%.+]]: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, [[PARAM_3_:%.+]]: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, [[PARAM_4_:%.+]]: i32, [[PARAM_5_:%.+]]: i32, [[PARAM_6_:%.+]]: i32, [[PARAM_7_:%.+]]: i32, [[PARAM_8_:%.+]]: i32, [[PARAM_9_:%.+]]: i32) {
               ^
<stdin>:2:40: note: scanning from here
 func.func @reduce_kernel_2d_0d1d2de3de(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32) {
                                       ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
         1: module { 
         2:  func.func @reduce_kernel_2d_0d1d2de3de(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32) { 
same:19                                            X~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ error: no match found
         3:  %c1_i32 = arith.constant 1 : i32 
same:19     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         4:  %c5_i32 = arith.constant 5 : i32 
same:19     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         5:  %c0_i32 = arith.constant 0 : i32 
same:19     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         6:  %0 = tt.addptr %arg1, %arg7 : !tt.ptr<f32>, i32 
same:19     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         7:  %1 = arith.sitofp %arg7 : i32 to f32 
same:19     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         .
         .
         .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax_reduce.mlir (16 of 216)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax_reduce.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental  /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:1 offset :11:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:1 offset :11:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:1 offset :11:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:1 offset :11:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<i32>) -> (), sym_name = "minmax_sgt", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<i32>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = dense<0> : tensor<4096xi32>}> : () -> tensor<4096xi32>
    %2 = "tt.reduce"(%1) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %3 = "arith.cmpi"(%arg1, %arg2) <{predicate = 4 : i64}> : (i32, i32) -> i1
      %4 = "arith.select"(%3, %arg1, %arg2) : (i1, i32, i32) -> i32
      "tt.reduce.return"(%4) : (i32) -> ()
    }) : (tensor<4096xi32>) -> i32
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
actual processing
processing user
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
!tt.ptr<i32>
~~~~
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<i32>) -> (), sym_name = "minmax_sgt", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<i32>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = dense<0> : tensor<4096xi32>}> : () -> tensor<4096xi32>
    %2 = "tt.reduce"(%1) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %4 = "arith.cmpi"(%arg1, %arg2) <{predicate = 4 : i64}> : (i32, i32) -> i1
      %5 = "arith.select"(%4, %arg1, %arg2) : (i1, i32, i32) -> i32
      "tt.reduce.return"(%5) : (i32) -> ()
    }) : (tensor<4096xi32>) -> i32
    %3 = "tts.create_ptr"(%arg0, %0) : (!tt.ptr<i32>, i32) -> !tt.ptr<i32>
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
total addptr count: 0
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:37 offset :12:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:37 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:37 offset :12:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:37 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<i32>) -> (), sym_name = "minmax_ugt", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<i32>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = dense<0> : tensor<4096xi32>}> : () -> tensor<4096xi32>
    %2 = "tt.reduce"(%1) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %3 = "arith.cmpi"(%arg1, %arg2) <{predicate = 8 : i64}> : (i32, i32) -> i1
      %4 = "arith.select"(%3, %arg1, %arg2) : (i1, i32, i32) -> i32
      "tt.reduce.return"(%4) : (i32) -> ()
    }) : (tensor<4096xi32>) -> i32
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
actual processing
processing user
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
!tt.ptr<i32>
~~~~
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<i32>) -> (), sym_name = "minmax_ugt", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<i32>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = dense<0> : tensor<4096xi32>}> : () -> tensor<4096xi32>
    %2 = "tt.reduce"(%1) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %4 = "arith.cmpi"(%arg1, %arg2) <{predicate = 8 : i64}> : (i32, i32) -> i1
      %5 = "arith.select"(%4, %arg1, %arg2) : (i1, i32, i32) -> i32
      "tt.reduce.return"(%5) : (i32) -> ()
    }) : (tensor<4096xi32>) -> i32
    %3 = "tts.create_ptr"(%arg0, %0) : (!tt.ptr<i32>, i32) -> !tt.ptr<i32>
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
total addptr count: 0
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:74 offset :12:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:74 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:74 offset :12:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:74 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<i32>) -> (), sym_name = "minmax_slt", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<i32>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = dense<0> : tensor<4096xi32>}> : () -> tensor<4096xi32>
    %2 = "tt.reduce"(%1) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %3 = "arith.cmpi"(%arg1, %arg2) <{predicate = 2 : i64}> : (i32, i32) -> i1
      %4 = "arith.select"(%3, %arg1, %arg2) : (i1, i32, i32) -> i32
      "tt.reduce.return"(%4) : (i32) -> ()
    }) : (tensor<4096xi32>) -> i32
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
actual processing
processing user
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
!tt.ptr<i32>
~~~~
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<i32>) -> (), sym_name = "minmax_slt", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<i32>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = dense<0> : tensor<4096xi32>}> : () -> tensor<4096xi32>
    %2 = "tt.reduce"(%1) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %4 = "arith.cmpi"(%arg1, %arg2) <{predicate = 2 : i64}> : (i32, i32) -> i1
      %5 = "arith.select"(%4, %arg1, %arg2) : (i1, i32, i32) -> i32
      "tt.reduce.return"(%5) : (i32) -> ()
    }) : (tensor<4096xi32>) -> i32
    %3 = "tts.create_ptr"(%arg0, %0) : (!tt.ptr<i32>, i32) -> !tt.ptr<i32>
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
total addptr count: 0
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:112 offset :12:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:112 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:112 offset :12:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:112 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<i32>) -> (), sym_name = "minmax_ult", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<i32>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = dense<0> : tensor<4096xi32>}> : () -> tensor<4096xi32>
    %2 = "tt.reduce"(%1) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %3 = "arith.cmpi"(%arg1, %arg2) <{predicate = 6 : i64}> : (i32, i32) -> i1
      %4 = "arith.select"(%3, %arg1, %arg2) : (i1, i32, i32) -> i32
      "tt.reduce.return"(%4) : (i32) -> ()
    }) : (tensor<4096xi32>) -> i32
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
actual processing
processing user
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
!tt.ptr<i32>
~~~~
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<i32>) -> (), sym_name = "minmax_ult", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<i32>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = dense<0> : tensor<4096xi32>}> : () -> tensor<4096xi32>
    %2 = "tt.reduce"(%1) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %4 = "arith.cmpi"(%arg1, %arg2) <{predicate = 6 : i64}> : (i32, i32) -> i1
      %5 = "arith.select"(%4, %arg1, %arg2) : (i1, i32, i32) -> i32
      "tt.reduce.return"(%5) : (i32) -> ()
    }) : (tensor<4096xi32>) -> i32
    %3 = "tts.create_ptr"(%arg0, %0) : (!tt.ptr<i32>, i32) -> !tt.ptr<i32>
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
total addptr count: 0
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:20:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
              ^
<stdin>:2:119: note: scanning from here
 func.func @minmax_sgt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:2:119: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_sgt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:16:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:57:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
              ^
<stdin>:24:119: note: scanning from here
 func.func @minmax_ugt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:24:119: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_ugt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:37:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:94:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
              ^
<stdin>:45:119: note: scanning from here
 func.func @minmax_slt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:45:119: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_slt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:59:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:132:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
              ^
<stdin>:67:119: note: scanning from here
 func.func @minmax_ult(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:67:119: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_ult(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:81:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
             ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
           1: module { 
           2:  func.func @minmax_sgt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) { 
dag:20'0                                                                                                                            X error: no match found
dag:20'1                                                                                                                              with "PARAM_0_" equal to "%arg0"
           3:  %c0 = arith.constant 0 : index 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           4:  %c-2147483648_i32 = arith.constant -2147483648 : i32 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           5:  %c0_i32 = arith.constant 0 : i32 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           6:  %0 = tensor.empty() : tensor<4096xi32> 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           7:  %1 = linalg.fill ins(%c0_i32 : i32) outs(%0 : tensor<4096xi32>) -> tensor<4096xi32> 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           .
           .
           .
          11:  (%in: i32, %init: i32) { 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~
          12:  %3 = arith.maxsi %in, %init : i32 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          13:  linalg.yield %3 : i32 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~
          14:  } 
dag:20'0      ~~~
          15:  %extracted = tensor.extract %reduced[] : tensor<i32> 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          16:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>> 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:20'2                   ?                                                                                                                                           possible intended match
          17:  affine.store %extracted, %reinterpret_cast[0] : memref<1xi32, strided<[1], offset: ?>> 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          18:  return 
dag:20'0      ~~~~~~~~
          19:  } 
dag:20'0      ~~~
          20: } 
dag:20'0      ~~
          21:  
dag:20'0      ~
          22: // ----- 
dag:20'0      ~~~~~~~~~
          23: module { 
dag:20'0      ~~~~~~~~~
          24:  func.func @minmax_ugt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) { 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~
dag:57'0                                                                                                                            X error: no match found
dag:57'1                                                                                                                              with "PARAM_0_" equal to "%arg0"
          25:  %c0 = arith.constant 0 : index 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          26:  %c0_i32 = arith.constant 0 : i32 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          27:  %0 = tensor.empty() : tensor<4096xi32> 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          28:  %1 = linalg.fill ins(%c0_i32 : i32) outs(%0 : tensor<4096xi32>) -> tensor<4096xi32> 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          29:  %2 = bufferization.alloc_tensor() : tensor<i32> 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           .
           .
           .
          32:  (%in: i32, %init: i32) { 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~
          33:  %3 = arith.maxui %in, %init : i32 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          34:  linalg.yield %3 : i32 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~
          35:  } 
dag:57'0      ~~~
          36:  %extracted = tensor.extract %reduced[] : tensor<i32> 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          37:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>> 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:57'2                   ?                                                                                                                                           possible intended match
          38:  affine.store %extracted, %reinterpret_cast[0] : memref<1xi32, strided<[1], offset: ?>> 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          39:  return 
dag:57'0      ~~~~~~~~
          40:  } 
dag:57'0      ~~~
          41: } 
dag:57'0      ~~
          42:  
dag:57'0      ~
          43: // ----- 
dag:57'0      ~~~~~~~~~
          44: module { 
dag:57'0      ~~~~~~~~~
          45:  func.func @minmax_slt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) { 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~
dag:94'0                                                                                                                            X error: no match found
dag:94'1                                                                                                                              with "PARAM_0_" equal to "%arg0"
          46:  %c0 = arith.constant 0 : index 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          47:  %c2147483647_i32 = arith.constant 2147483647 : i32 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          48:  %c0_i32 = arith.constant 0 : i32 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          49:  %0 = tensor.empty() : tensor<4096xi32> 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          50:  %1 = linalg.fill ins(%c0_i32 : i32) outs(%0 : tensor<4096xi32>) -> tensor<4096xi32> 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           .
           .
           .
          54:  (%in: i32, %init: i32) { 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~
          55:  %3 = arith.minsi %in, %init : i32 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          56:  linalg.yield %3 : i32 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~
          57:  } 
dag:94'0      ~~~
          58:  %extracted = tensor.extract %reduced[] : tensor<i32> 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          59:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>> 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:94'2                   ?                                                                                                                                           possible intended match
          60:  affine.store %extracted, %reinterpret_cast[0] : memref<1xi32, strided<[1], offset: ?>> 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          61:  return 
dag:94'0      ~~~~~~~~
          62:  } 
dag:94'0      ~~~
          63: } 
dag:94'0      ~~
          64:  
dag:94'0      ~
          65: // ----- 
dag:94'0      ~~~~~~~~~
          66: module { 
dag:94'0      ~~~~~~~~~
          67:  func.func @minmax_ult(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) { 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~
dag:132'0                                                                                                                           X error: no match found
dag:132'1                                                                                                                             with "PARAM_0_" equal to "%arg0"
          68:  %c0 = arith.constant 0 : index 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          69:  %c-1_i32 = arith.constant -1 : i32 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          70:  %c0_i32 = arith.constant 0 : i32 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          71:  %0 = tensor.empty() : tensor<4096xi32> 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          72:  %1 = linalg.fill ins(%c0_i32 : i32) outs(%0 : tensor<4096xi32>) -> tensor<4096xi32> 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           .
           .
           .
          76:  (%in: i32, %init: i32) { 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~
          77:  %3 = arith.minui %in, %init : i32 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          78:  linalg.yield %3 : i32 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~
          79:  } 
dag:132'0     ~~~
          80:  %extracted = tensor.extract %reduced[] : tensor<i32> 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          81:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>> 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:132'2                  ?                                                                                                                                           possible intended match
          82:  affine.store %extracted, %reinterpret_cast[0] : memref<1xi32, strided<[1], offset: ?>> 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          83:  return 
dag:132'0     ~~~~~~~~
          84:  } 
dag:132'0     ~~~
          85: } 
dag:132'0     ~~
          86:  
dag:132'0     ~
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_chain.mlir (17 of 216)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/addptr_chain.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :16:12: remark: PtrAnalysis: scalar loadOp will not be rewritten
      %6 = tt.load %2 : !tt.ptr<f32>
           ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :16:12: note: see current operation: %16 = tt.load %8 : !tt.ptr<f32>
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :16:12: remark: PtrAnalysis: Failed to rewrite LoadOp
      %6 = tt.load %2 : !tt.ptr<f32>
           ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :16:12: note: see current operation: %16 = tt.load %8 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :17:12: remark: PtrAnalysis: scalar loadOp will not be rewritten
      %7 = tt.load %3 : !tt.ptr<f32>
           ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :17:12: note: see current operation: %17 = tt.load %10 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :17:12: remark: PtrAnalysis: Failed to rewrite LoadOp
      %7 = tt.load %3 : !tt.ptr<f32>
           ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :17:12: note: see current operation: %17 = tt.load %10 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :18:7: remark: PtrAnalysis: scalar storeOp will not be rewritten
      tt.store %4, %6 : !tt.ptr<f32>
      ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :18:7: note: see current operation: tt.store %13, %16 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :18:7: remark: PtrAnalysis: Failed to rewrite StoreOp
      tt.store %4, %6 : !tt.ptr<f32>
      ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :18:7: note: see current operation: tt.store %13, %16 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :19:7: remark: PtrAnalysis: scalar storeOp will not be rewritten
      tt.store %5, %7 : !tt.ptr<f32>
      ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :19:7: note: see current operation: tt.store %15, %17 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :19:7: remark: PtrAnalysis: Failed to rewrite StoreOp
      tt.store %5, %7 : !tt.ptr<f32>
      ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :19:7: note: see current operation: tt.store %15, %17 : !tt.ptr<f32>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, !tt.ptr<f32>) -> (), sym_name = "addptr", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 2 : i32}> : () -> i32
    %3 = "arith.constant"() <{value = 10 : i32}> : () -> i32
    %4 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
    %6 = "tt.addptr"(%1, %5) : (i32, i32) -> !tt.ptr<f32>
    %7 = "tt.addptr"(%0, %5) : (i32, i32) -> !tt.ptr<f32>
    "scf.for"(%4, %3, %2) ({
    ^bb0(%arg2: i32):
      %8 = "tt.addptr"(%6, %arg2) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      %9 = "tt.addptr"(%8, %5) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      %10 = "tt.addptr"(%7, %arg2) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      %11 = "tt.addptr"(%10, %5) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      %12 = "tt.load"(%8) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> : (!tt.ptr<f32>) -> f32
      %13 = "tt.load"(%9) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> : (!tt.ptr<f32>) -> f32
      "tt.store"(%10, %12) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<f32>, f32) -> ()
      "tt.store"(%11, %13) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<f32>, f32) -> ()
      "scf.yield"() : () -> ()
    }) : (i32, i32, i32) -> ()
    "tt.return"() : () -> ()
  }) {noinline = false} : () -> ()
}) : () -> ()
processing val
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
%6 = "tt.addptr"(%1, %5) : (i32, i32) -> !tt.ptr<f32>
actual processing
processing user
%6 = "tt.addptr"(%1, %5) : (i32, i32) -> !tt.ptr<f32>
~~~~
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
%8 = "tt.addptr"(%0, %5) : (i32, i32) -> !tt.ptr<f32>
actual processing
processing user
%8 = "tt.addptr"(%0, %5) : (i32, i32) -> !tt.ptr<f32>
~~~~
processing val
%7 = "tt.addptr"(%1, %5) : (i32, i32) -> !tt.ptr<f32>
these are the uses:
%10 = "tt.addptr"(%7, %arg2) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
actual processing
processing user
%10 = "tt.addptr"(%7, %arg2) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
~~~~
processing val
%9 = "tt.addptr"(%0, %5) : (i32, i32) -> !tt.ptr<f32>
these are the uses:
%13 = "tt.addptr"(%9, %arg2) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
actual processing
processing user
%13 = "tt.addptr"(%9, %arg2) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
~~~~
processing val
%11 = "tt.addptr"(%7, %arg2) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
these are the uses:
%16 = "tt.load"(%11) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> : (!tt.ptr<f32>) -> f32
%12 = "tt.addptr"(%11, %5) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
actual processing
processing user
%16 = "tt.load"(%11) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> : (!tt.ptr<f32>) -> f32
!tt.ptr<f32>
processing user
%12 = "tt.addptr"(%11, %5) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
~~~~
processing val
%15 = "tt.addptr"(%9, %arg2) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
these are the uses:
"tt.store"(%15, %18) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<f32>, f32) -> ()
%16 = "tt.addptr"(%15, %5) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
actual processing
processing user
"tt.store"(%15, %18) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<f32>, f32) -> ()
!tt.ptr<f32>
processing user
%16 = "tt.addptr"(%15, %5) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
~~~~
processing val
%13 = "tt.addptr"(%11, %5) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
these are the uses:
%20 = "tt.load"(%13) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> : (!tt.ptr<f32>) -> f32
actual processing
processing user
%20 = "tt.load"(%13) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> : (!tt.ptr<f32>) -> f32
!tt.ptr<f32>
~~~~
processing val
%17 = "tt.addptr"(%15, %5) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
these are the uses:
"tt.store"(%17, %21) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<f32>, f32) -> ()
actual processing
processing user
"tt.store"(%17, %21) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<f32>, f32) -> ()
!tt.ptr<f32>
~~~~
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, !tt.ptr<f32>) -> (), sym_name = "addptr", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 2 : i32}> : () -> i32
    %3 = "arith.constant"() <{value = 10 : i32}> : () -> i32
    %4 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
    %6 = "arith.addi"(%1, %5) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %7 = "tt.addptr"(%1, %5) : (i32, i32) -> !tt.ptr<f32>
    %8 = "arith.addi"(%0, %5) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %9 = "tt.addptr"(%0, %5) : (i32, i32) -> !tt.ptr<f32>
    "scf.for"(%4, %3, %2) ({
    ^bb0(%arg2: i32):
      %10 = "arith.addi"(%7, %arg2) <{overflowFlags = #arith.overflow<none>}> : (!tt.ptr<f32>, i32) -> i32
      %11 = "tt.addptr"(%7, %arg2) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      %12 = "arith.addi"(%11, %5) <{overflowFlags = #arith.overflow<none>}> : (!tt.ptr<f32>, i32) -> i32
      %13 = "tt.addptr"(%11, %5) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      %14 = "arith.addi"(%9, %arg2) <{overflowFlags = #arith.overflow<none>}> : (!tt.ptr<f32>, i32) -> i32
      %15 = "tt.addptr"(%9, %arg2) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      %16 = "arith.addi"(%15, %5) <{overflowFlags = #arith.overflow<none>}> : (!tt.ptr<f32>, i32) -> i32
      %17 = "tt.addptr"(%15, %5) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      %18 = "tts.create_ptr"(%arg0, %10) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      %19 = "tt.load"(%11) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> : (!tt.ptr<f32>) -> f32
      %20 = "tts.create_ptr"(%arg0, %12) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      %21 = "tt.load"(%13) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> : (!tt.ptr<f32>) -> f32
      %22 = "tts.create_ptr"(%arg1, %14) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      "tt.store"(%15, %19) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<f32>, f32) -> ()
      %23 = "tts.create_ptr"(%arg1, %16) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      "tt.store"(%17, %21) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<f32>, f32) -> ()
      "scf.yield"() : () -> ()
    }) : (i32, i32, i32) -> ()
    "tt.return"() : () -> ()
  }) {noinline = false} : () -> ()
}) : () -> ()
total addptr count: 6
deleting
%13 = "tt.addptr"(%11, %5) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
deleting
%9 = "tt.addptr"(%0, %5) : (i32, i32) -> !tt.ptr<f32>
deleting
%11 = "tt.addptr"(%7, %arg2) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
deleting
%15 = "tt.addptr"(%9, %arg2) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
deleting
%7 = "tt.addptr"(%1, %5) : (i32, i32) -> !tt.ptr<f32>
deleting
%17 = "tt.addptr"(%15, %5) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:27:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: %c2 = arith.constant 2 : index
              ^
<stdin>:2:137: note: scanning from here
 func.func @addptr(%arg0: memref<*xf32>, %arg1: memref<*xf32>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) {
                                                                                                                                        ^
<stdin>:4:6: note: possible intended match here
 %c2_i32 = arith.constant 2 : i32
     ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module { 
          2:  func.func @addptr(%arg0: memref<*xf32>, %arg1: memref<*xf32>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) { 
dag:27'0                                                                                                                                             X error: no match found
          3:  %c0_i32 = arith.constant 0 : i32 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %c2_i32 = arith.constant 2 : i32 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:27'1          ?                             possible intended match
          5:  %c10_i32 = arith.constant 10 : i32 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          6:  %c1_i32 = arith.constant 1 : i32 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  scf.for %arg8 = %c0_i32 to %c10_i32 step %c2_i32 : i32 { 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          8:  %0 = arith.addi %arg8, %c1_i32 : i32 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          9:  %1 = arith.addi %arg8, %c2_i32 : i32 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          .
          .
          .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/block_ptr_complex_offset.mlir (18 of 216)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/block_ptr_complex_offset.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --structured-to-memref --split-input-file /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/block_ptr_complex_offset.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/block_ptr_complex_offset.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --structured-to-memref --split-input-file /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/block_ptr_complex_offset.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/block_ptr_complex_offset.mlir
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/block_ptr_complex_offset.mlir:19:11: error: CHECK: expected string not found in input
// CHECK: func.func @fused_attention_fwd_kernel(%arg0: memref<*xbf16>, %arg1: memref<*xbf16>, %arg2: i64, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) -> tensor<128x128xbf16> {
          ^
<stdin>:1:9: note: scanning from here
module {
        ^
<stdin>:2:2: note: possible intended match here
 func.func @fused_attention_fwd_kernel(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>, %arg2: i64, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) -> tensor<128x128xbf16> {
 ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/block_ptr_complex_offset.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
            1: module { 
check:19'0             X error: no match found
            2:  func.func @fused_attention_fwd_kernel(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>, %arg2: i64, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) -> tensor<128x128xbf16> { 
check:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
check:19'1      ?                                                                                                                                                                                                            possible intended match
            3:  %c1 = arith.constant 1 : index 
check:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
            4:  %c0 = arith.constant 0 : index 
check:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
            5:  %c128 = arith.constant 128 : index 
check:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
            6:  %0 = arith.remsi %arg8, %arg3 : i32 
check:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
            7:  %1 = arith.extsi %0 : i32 to i64 
check:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
            .
            .
            .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_loop.mlir (19 of 216)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_loop.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --canonicalize --triton-arith-to-linalg --structured-to-memref /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --canonicalize --triton-arith-to-linalg --structured-to-memref /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop.mlir
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop.mlir:19:16: error: CHECK-SAME: expected string not found in input
// CHECK-SAME: ([[PARAM_0_:%.+]]: memref<*xf32> {tt.divisibility = 16 : i32}, [[PARAM_1_:%.+]]: i32, [[PARAM_2_:%.+]]: i32, [[PARAM_3_:%.+]]: i32, [[PARAM_4_:%.+]]: i32, [[PARAM_5_:%.+]]: i32, [[PARAM_6_:%.+]]: i32) {
               ^
<stdin>:2:32: note: scanning from here
 func.func @reduce_kernel_2d_0d(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32) {
                               ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
         1: module { 
         2:  func.func @reduce_kernel_2d_0d(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32) { 
same:19                                    X~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ error: no match found
         3:  %c8_i32 = arith.constant 8 : i32 
same:19     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         4:  %c0_i32 = arith.constant 0 : i32 
same:19     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         5:  %c1_i32 = arith.constant 1 : i32 
same:19     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         6:  %0 = scf.for %arg13 = %c0_i32 to %c8_i32 step %c1_i32 iter_args(%arg14 = %arg0) -> (!tt.ptr<f32>) : i32 { 
same:19     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         7:  %1 = arith.sitofp %arg13 : i32 to f32 
same:19     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         .
         .
         .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_addi_reduce.mlir (20 of 216)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_addi_reduce.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental  /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir:1 offset :11:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir:1 offset :11:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir:1 offset :11:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir:1 offset :11:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<i32>) -> (), sym_name = "addi", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<i32>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = dense<0> : tensor<4096xi32>}> : () -> tensor<4096xi32>
    %2 = "tt.reduce"(%1) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %3 = "arith.addi"(%arg1, %arg2) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
      "tt.reduce.return"(%3) : (i32) -> ()
    }) : (tensor<4096xi32>) -> i32
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
actual processing
processing user
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
!tt.ptr<i32>
~~~~
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<i32>) -> (), sym_name = "addi", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<i32>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = dense<0> : tensor<4096xi32>}> : () -> tensor<4096xi32>
    %2 = "tt.reduce"(%1) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %4 = "arith.addi"(%arg1, %arg2) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
      "tt.reduce.return"(%4) : (i32) -> ()
    }) : (tensor<4096xi32>) -> i32
    %3 = "tts.create_ptr"(%arg0, %0) : (!tt.ptr<i32>, i32) -> !tt.ptr<i32>
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
total addptr count: 0
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir:19:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
              ^
<stdin>:2:113: note: scanning from here
 func.func @addi(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                ^
<stdin>:2:113: note: with "PARAM_0_" equal to "%arg0"
 func.func @addi(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                ^
<stdin>:15:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
             ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module { 
          2:  func.func @addi(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) { 
dag:19'0                                                                                                                     X error: no match found
dag:19'1                                                                                                                       with "PARAM_0_" equal to "%arg0"
          3:  %c0 = arith.constant 0 : index 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %c0_i32 = arith.constant 0 : i32 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %0 = tensor.empty() : tensor<4096xi32> 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          6:  %1 = linalg.fill ins(%c0_i32 : i32) outs(%0 : tensor<4096xi32>) -> tensor<4096xi32> 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  %2 = bufferization.alloc_tensor() : tensor<i32> 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          .
          .
          .
         10:  (%in: i32, %init: i32) { 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~
         11:  %3 = arith.addi %in, %init : i32 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         12:  linalg.yield %3 : i32 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~
         13:  } 
dag:19'0     ~~~
         14:  %extracted = tensor.extract %reduced[] : tensor<i32> 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         15:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>> 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:19'2                  ?                                                                                                                                           possible intended match
         16:  affine.store %extracted, %reinterpret_cast[0] : memref<1xi32, strided<[1], offset: ?>> 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         17:  return 
dag:19'0     ~~~~~~~~
         18:  } 
dag:19'0     ~~~
         19: } 
dag:19'0     ~~
         20:  
dag:19'0     ~
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_loopback.mlir (21 of 216)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_loopback.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :11:11: remark: PtrAnalysis: scalar loadOp will not be rewritten
    %10 = tt.load %0 {cache = 1 : i32, evict = 1 : i32, isVolatile = false}: !tt.ptr<bf16>
          ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :11:11: note: see current operation: %4 = tt.load %1 : !tt.ptr<bf16>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :11:11: remark: PtrAnalysis: Failed to rewrite LoadOp
    %10 = tt.load %0 {cache = 1 : i32, evict = 1 : i32, isVolatile = false}: !tt.ptr<bf16>
          ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :11:11: note: see current operation: %4 = tt.load %1 : !tt.ptr<bf16>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :12:5: remark: PtrAnalysis: scalar storeOp will not be rewritten
    tt.store %1, %10 : !tt.ptr<bf16>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :12:5: note: see current operation: tt.store %3, %4 : !tt.ptr<bf16>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :12:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %1, %10 : !tt.ptr<bf16>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :12:5: note: see current operation: tt.store %3, %4 : !tt.ptr<bf16>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<bf16>, !tt.ptr<bf16>, i32) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>, %arg2: i32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "tt.addptr"(%1, %arg2) : (i32, i32) -> !tt.ptr<bf16>
    %3 = "tt.addptr"(%0, %arg2) : (i32, i32) -> !tt.ptr<bf16>
    %4 = "tt.load"(%2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> : (!tt.ptr<bf16>) -> bf16
    "tt.store"(%3, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<bf16>, bf16) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
processing val
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
%2 = "tt.addptr"(%1, %arg2) : (i32, i32) -> !tt.ptr<bf16>
actual processing
processing user
%2 = "tt.addptr"(%1, %arg2) : (i32, i32) -> !tt.ptr<bf16>
~~~~
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
%4 = "tt.addptr"(%0, %arg2) : (i32, i32) -> !tt.ptr<bf16>
actual processing
processing user
%4 = "tt.addptr"(%0, %arg2) : (i32, i32) -> !tt.ptr<bf16>
~~~~
processing val
%3 = "tt.addptr"(%1, %arg2) : (i32, i32) -> !tt.ptr<bf16>
these are the uses:
%6 = "tt.load"(%3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> : (!tt.ptr<bf16>) -> bf16
actual processing
processing user
%6 = "tt.load"(%3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> : (!tt.ptr<bf16>) -> bf16
!tt.ptr<bf16>
~~~~
processing val
%5 = "tt.addptr"(%0, %arg2) : (i32, i32) -> !tt.ptr<bf16>
these are the uses:
"tt.store"(%5, %7) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<bf16>, bf16) -> ()
actual processing
processing user
"tt.store"(%5, %7) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<bf16>, bf16) -> ()
!tt.ptr<bf16>
~~~~
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<bf16>, !tt.ptr<bf16>, i32) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>, %arg2: i32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.addi"(%1, %arg2) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %3 = "tt.addptr"(%1, %arg2) : (i32, i32) -> !tt.ptr<bf16>
    %4 = "arith.addi"(%0, %arg2) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %5 = "tt.addptr"(%0, %arg2) : (i32, i32) -> !tt.ptr<bf16>
    %6 = "tts.create_ptr"(%arg0, %2) : (!tt.ptr<bf16>, i32) -> !tt.ptr<bf16>
    %7 = "tt.load"(%3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> : (!tt.ptr<bf16>) -> bf16
    %8 = "tts.create_ptr"(%arg1, %4) : (!tt.ptr<bf16>, i32) -> !tt.ptr<bf16>
    "tt.store"(%5, %7) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<bf16>, bf16) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
total addptr count: 2
deleting
%5 = "tt.addptr"(%0, %arg2) : (i32, i32) -> !tt.ptr<bf16>
deleting
%3 = "tt.addptr"(%1, %arg2) : (i32, i32) -> !tt.ptr<bf16>
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:22:11: error: CHECK: expected string not found in input
// CHECK: [[LOAD_VAR_reinterpret_cast_MEM_:%.+]] = affine.load [[VAR_reinterpret_cast_]][0] : memref<1xbf16, strided<[1], offset: ?>>
          ^
<stdin>:6:155: note: scanning from here
 %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>>
                                                                                                                                                          ^
<stdin>:6:155: note: with "VAR_reinterpret_cast_" equal to "%reinterpret_cast"
 %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>>
                                                                                                                                                          ^
<stdin>:7:19: note: possible intended match here
 affine.store %1, %reinterpret_cast_0[0] : memref<1xbf16, strided<[1], offset: ?>>
                  ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
            1: module { 
            2:  func.func @kernel(%arg0: memref<*xbf16>, %arg1: memref<*xbf16>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) { 
            3:  %0 = arith.index_cast %arg2 : i32 to index 
            4:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>> 
            5:  %1 = affine.load %reinterpret_cast[0] : memref<1xbf16, strided<[1], offset: ?>> 
            6:  %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>> 
check:22'0                                                                                                                                                               X error: no match found
check:22'1                                                                                                                                                                 with "VAR_reinterpret_cast_" equal to "%reinterpret_cast"
            7:  affine.store %1, %reinterpret_cast_0[0] : memref<1xbf16, strided<[1], offset: ?>> 
check:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
check:22'2                       ?                                                                 possible intended match
            8:  return 
check:22'0     ~~~~~~~~
            9:  } 
check:22'0     ~~~
           10: } 
check:22'0     ~~
           11:  
check:22'0     ~
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_scalar.mlir (22 of 216)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_scalar.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir:1 offset :14:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %res, %3 : !tt.ptr<bf16>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir:1 offset :14:5: note: see current operation: tt.store %arg1, %5 : !tt.ptr<bf16>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir:1 offset :14:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %res, %3 : !tt.ptr<bf16>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir:1 offset :14:5: note: see current operation: tt.store %arg1, %5 : !tt.ptr<bf16>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<bf16>, !tt.ptr<bf16>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "tts.make_tptr"(%arg0) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 128>, static_offsets = array<i64: 0>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<bf16>) -> tensor<128x!tt.ptr<bf16>>
    %3 = "tts.load"(%2) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x!tt.ptr<bf16>>) -> tensor<128xbf16>
    %4 = "tt.reduce"(%3) <{axis = 0 : i32}> ({
    ^bb0(%arg2: bf16, %arg3: bf16):
      %5 = "arith.addf"(%arg2, %arg3) <{fastmath = #arith.fastmath<none>}> : (bf16, bf16) -> bf16
      "tt.reduce.return"(%5) : (bf16) -> ()
    }) : (tensor<128xbf16>) -> bf16
    "tt.store"(%0, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, bf16) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
processing val
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
actual processing
~~~~
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
"tt.store"(%0, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, bf16) -> ()
actual processing
processing user
"tt.store"(%0, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, bf16) -> ()
!tt.ptr<bf16>
~~~~
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<bf16>, !tt.ptr<bf16>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "tts.make_tptr"(%arg0) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 128>, static_offsets = array<i64: 0>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<bf16>) -> tensor<128x!tt.ptr<bf16>>
    %3 = "tts.load"(%2) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x!tt.ptr<bf16>>) -> tensor<128xbf16>
    %4 = "tt.reduce"(%3) <{axis = 0 : i32}> ({
    ^bb0(%arg2: bf16, %arg3: bf16):
      %6 = "arith.addf"(%arg2, %arg3) <{fastmath = #arith.fastmath<none>}> : (bf16, bf16) -> bf16
      "tt.reduce.return"(%6) : (bf16) -> ()
    }) : (tensor<128xbf16>) -> bf16
    %5 = "tts.create_ptr"(%arg1, %0) : (!tt.ptr<bf16>, i32) -> !tt.ptr<bf16>
    "tt.store"(%0, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, bf16) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
total addptr count: 0
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir:22:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_1_]] to offset: [0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>>
              ^
<stdin>:2:139: note: scanning from here
 func.func @kernel(%arg0: memref<*xbf16>, %arg1: memref<*xbf16>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) {
                                                                                                                                          ^
<stdin>:2:139: note: with "PARAM_1_" equal to "%arg1"
 func.func @kernel(%arg0: memref<*xbf16>, %arg1: memref<*xbf16>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) {
                                                                                                                                          ^
<stdin>:19:16: note: possible intended match here
 %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%c0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>>
               ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module { 
          2:  func.func @kernel(%arg0: memref<*xbf16>, %arg1: memref<*xbf16>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) { 
dag:22'0                                                                                                                                               X error: no match found
dag:22'1                                                                                                                                                 with "PARAM_1_" equal to "%arg1"
          3:  %c0 = arith.constant 0 : index 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %cst = arith.constant 0.000000e+00 : f32 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [128], strides: [1] : memref<*xbf16> to memref<128xbf16, strided<[1]>> 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          6:  %alloc = memref.alloc() : memref<128xbf16> 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  memref.copy %reinterpret_cast, %alloc : memref<128xbf16, strided<[1]>> to memref<128xbf16> 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          .
          .
          .
         14:  %4 = arith.addf %3, %init : f32 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         15:  linalg.yield %4 : f32 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~
         16:  } 
dag:22'0     ~~~
         17:  %extracted = tensor.extract %reduced[] : tensor<f32> 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         18:  %2 = arith.truncf %extracted : f32 to bf16 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         19:  %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%c0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>> 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:22'2                    ?                                                                                                                                             possible intended match
         20:  affine.store %2, %reinterpret_cast_0[0] : memref<1xbf16, strided<[1], offset: ?>> 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         21:  return 
dag:22'0     ~~~~~~~~
         22:  } 
dag:22'0     ~~~
         23: } 
dag:22'0     ~~
         24:  
dag:22'0     ~
>>>>>>

--

********************
XFAIL: TRITON-SHARED :: Conversion/StructuredToMemref/wraparound_unsupported_add_offset.mlir (23 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_for_accumulation.mlir (24 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/nested_loops.mlir (25 of 216)
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir (26 of 216)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :32:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save0, %5 : tensor<1024x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :32:5: note: see current operation: tt.store %arg3, %13 : tensor<1024x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :32:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save0, %5 : tensor<1024x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :32:5: note: see current operation: tt.store %arg3, %13 : tensor<1024x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :33:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save1, %6 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :33:5: note: see current operation: tt.store %arg4, %14 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :33:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save1, %6 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :33:5: note: see current operation: tt.store %arg4, %14 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :34:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save2, %7 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :34:5: note: see current operation: tt.store %arg5, %15 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :34:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save2, %7 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :34:5: note: see current operation: tt.store %arg5, %15 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :35:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save3, %10 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :35:5: note: see current operation: tt.store %arg6, %16 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :35:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save3, %10 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :35:5: note: see current operation: tt.store %arg6, %16 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :36:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save4, %11 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :36:5: note: see current operation: tt.store %arg7, %17 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :36:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save4, %11 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :36:5: note: see current operation: tt.store %arg7, %17 : tensor<1024x!tt.ptr<f32>>
tensor<1024x!tt.ptr<bf16>>
tensor<1024x!tt.ptr<f32>>
tensor<1024x!tt.ptr<f32>>
tensor<1024x!tt.ptr<f32>>
tensor<1024x!tt.ptr<f32>>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, !tt.ptr<i32>, !tt.ptr<f16>, tensor<1024x!tt.ptr<bf16>>, tensor<1024x!tt.ptr<f32>>, tensor<1024x!tt.ptr<f32>>, tensor<1024x!tt.ptr<f32>>, tensor<1024x!tt.ptr<f32>>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<i32>, %arg2: !tt.ptr<f16>, %arg3: tensor<1024x!tt.ptr<bf16>>, %arg4: tensor<1024x!tt.ptr<f32>>, %arg5: tensor<1024x!tt.ptr<f32>>, %arg6: tensor<1024x!tt.ptr<f32>>, %arg7: tensor<1024x!tt.ptr<f32>>):
    %0 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
    %1 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
    %2 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
    %3 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
    %4 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
    %5 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %7 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %8 = "tts.make_tptr"(%arg0) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: 0>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>) -> tensor<1024x!tt.ptr<f32>>
    %9 = "tts.make_tptr"(%arg1) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: 0>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<i32>) -> tensor<1024x!tt.ptr<i32>>
    %10 = "tts.make_tptr"(%arg2) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: 0>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f16>) -> tensor<1024x!tt.ptr<f16>>
    %11 = "tts.load"(%8) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %12 = "tts.load"(%9) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<i32>>) -> tensor<1024xi32>
    %13 = "tts.load"(%10) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f16>>) -> tensor<1024xf16>
    %14 = "arith.truncf"(%11) : (tensor<1024xf32>) -> tensor<1024xbf16>
    %15 = "math.exp"(%11) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>) -> tensor<1024xf32>
    %16 = "arith.sitofp"(%12) : (tensor<1024xi32>) -> tensor<1024xf32>
    %17 = "arith.extf"(%13) : (tensor<1024xf16>) -> tensor<1024xf32>
    %18 = "math.sqrt"(%11) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>) -> tensor<1024xf32>
    "tt.store"(%4, %14) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xbf16>) -> ()
    "tt.store"(%3, %15) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
    "tt.store"(%2, %16) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
    "tt.store"(%1, %17) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
    "tt.store"(%0, %18) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
processing val
%7 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
actual processing
~~~~
processing val
%6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
actual processing
~~~~
processing val
%5 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
actual processing
~~~~
processing val
%4 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
these are the uses:
"tt.store"(%4, %14) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xbf16>) -> ()
actual processing
processing user
"tt.store"(%4, %14) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xbf16>) -> ()
tensor<1024x!tt.ptr<bf16>>
~~~~
processing val
%3 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
these are the uses:
"tt.store"(%3, %15) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
actual processing
processing user
"tt.store"(%3, %15) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
tensor<1024x!tt.ptr<f32>>
~~~~
processing val
%2 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
these are the uses:
"tt.store"(%2, %16) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
actual processing
processing user
"tt.store"(%2, %16) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
tensor<1024x!tt.ptr<f32>>
~~~~
processing val
%1 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
these are the uses:
"tt.store"(%1, %17) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
actual processing
processing user
"tt.store"(%1, %17) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
tensor<1024x!tt.ptr<f32>>
~~~~
processing val
%0 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
these are the uses:
"tt.store"(%0, %18) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
actual processing
processing user
"tt.store"(%0, %18) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
tensor<1024x!tt.ptr<f32>>
~~~~
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, !tt.ptr<i32>, !tt.ptr<f16>, tensor<1024x!tt.ptr<bf16>>, tensor<1024x!tt.ptr<f32>>, tensor<1024x!tt.ptr<f32>>, tensor<1024x!tt.ptr<f32>>, tensor<1024x!tt.ptr<f32>>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<i32>, %arg2: !tt.ptr<f16>, %arg3: tensor<1024x!tt.ptr<bf16>>, %arg4: tensor<1024x!tt.ptr<f32>>, %arg5: tensor<1024x!tt.ptr<f32>>, %arg6: tensor<1024x!tt.ptr<f32>>, %arg7: tensor<1024x!tt.ptr<f32>>):
    %0 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
    %1 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
    %2 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
    %3 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
    %4 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
    %5 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %7 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %8 = "tts.make_tptr"(%arg0) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: 0>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>) -> tensor<1024x!tt.ptr<f32>>
    %9 = "tts.make_tptr"(%arg1) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: 0>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<i32>) -> tensor<1024x!tt.ptr<i32>>
    %10 = "tts.make_tptr"(%arg2) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: 0>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f16>) -> tensor<1024x!tt.ptr<f16>>
    %11 = "tts.load"(%8) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %12 = "tts.load"(%9) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<i32>>) -> tensor<1024xi32>
    %13 = "tts.load"(%10) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f16>>) -> tensor<1024xf16>
    %14 = "arith.truncf"(%11) : (tensor<1024xf32>) -> tensor<1024xbf16>
    %15 = "math.exp"(%11) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>) -> tensor<1024xf32>
    %16 = "arith.sitofp"(%12) : (tensor<1024xi32>) -> tensor<1024xf32>
    %17 = "arith.extf"(%13) : (tensor<1024xf16>) -> tensor<1024xf32>
    %18 = "math.sqrt"(%11) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>) -> tensor<1024xf32>
    %19 = "tts.create_ptr"(%arg3, %4) : (tensor<1024x!tt.ptr<bf16>>, tensor<1024xi32>) -> tensor<1024x!tt.ptr<bf16>>
    "tt.store"(%4, %14) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xbf16>) -> ()
    %20 = "tts.create_ptr"(%arg4, %3) : (tensor<1024x!tt.ptr<f32>>, tensor<1024xi32>) -> tensor<1024x!tt.ptr<f32>>
    "tt.store"(%3, %15) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
    %21 = "tts.create_ptr"(%arg5, %2) : (tensor<1024x!tt.ptr<f32>>, tensor<1024xi32>) -> tensor<1024x!tt.ptr<f32>>
    "tt.store"(%2, %16) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
    %22 = "tts.create_ptr"(%arg6, %1) : (tensor<1024x!tt.ptr<f32>>, tensor<1024xi32>) -> tensor<1024x!tt.ptr<f32>>
    "tt.store"(%1, %17) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
    %23 = "tts.create_ptr"(%arg7, %0) : (tensor<1024x!tt.ptr<f32>>, tensor<1024xi32>) -> tensor<1024x!tt.ptr<f32>>
    "tt.store"(%0, %18) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
total addptr count: 0
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:43:16: error: CHECK-SAME: expected string not found in input
// CHECK-SAME: ([[PARAM_0_:%.+]]: memref<*xf32>, [[PARAM_1_:%.+]]: memref<*xi32>, [[PARAM_2_:%.+]]: memref<*xf16>, [[PARAM_3_:%.+]]: tensor<1024x!tt.ptr<bf16>>, [[PARAM_4_:%.+]]: tensor<1024x!tt.ptr<f32>>, [[PARAM_5_:%.+]]: tensor<1024x!tt.ptr<f32>>, [[PARAM_6_:%.+]]: tensor<1024x!tt.ptr<f32>>, [[PARAM_7_:%.+]]: tensor<1024x!tt.ptr<f32>>, [[PARAM_8_:%.+]]: i32, [[PARAM_9_:%.+]]: i32, [[PARAM_10_:%.+]]: i32, [[PARAM_11_:%.+]]: i32, [[PARAM_12_:%.+]]: i32, [[PARAM_13_:%.+]]: i32) {
               ^
<stdin>:3:19: note: scanning from here
 func.func @kernel(%arg0: memref<*xf32>, %arg1: memref<*xi32>, %arg2: memref<*xf16>, %arg3: memref<1024xbf16>, %arg4: memref<1024xf32>, %arg5: memref<1024xf32>, %arg6: memref<1024xf32>, %arg7: memref<1024xf32>, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32) {
                  ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
         1: #map = affine_map<(d0) -> (d0)> 
         2: module { 
         3:  func.func @kernel(%arg0: memref<*xf32>, %arg1: memref<*xi32>, %arg2: memref<*xf16>, %arg3: memref<1024xbf16>, %arg4: memref<1024xf32>, %arg5: memref<1024xf32>, %arg6: memref<1024xf32>, %arg7: memref<1024xf32>, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32) { 
same:43                       X~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ error: no match found
         4:  %c0 = arith.constant 0 : index 
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         5:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [1024], strides: [1] : memref<*xf32> to memref<1024xf32, strided<[1]>> 
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         6:  %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [0], sizes: [1024], strides: [1] : memref<*xi32> to memref<1024xi32, strided<[1]>> 
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         7:  %reinterpret_cast_1 = memref.reinterpret_cast %arg2 to offset: [0], sizes: [1024], strides: [1] : memref<*xf16> to memref<1024xf16, strided<[1]>> 
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         8:  %alloc = memref.alloc() : memref<1024xf32> 
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         .
         .
         .
>>>>>>

--

********************
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/wraparound_stacked.mlir (27 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/nested_loops.mlir (28 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/ridiculously_nested_loops.mlir (29 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/dot.mlir (30 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/convert_argmin_argmax_2d.mlir (31 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_extern_elementwise.mlir (32 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/triton-to-structured-prepass.mlir (33 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/kernel-05-layer-norm-fwd.mlir (34 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_extern_elementwise.mlir (35 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/dot.mlir (36 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/tensor_indices_loop_iterarg_with_masks.mlir (37 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/kernel-03-matrix-multiplication.mlir (38 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/block_ptr_advance.mlir (39 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_loopback.mlir (40 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_splat_2d.mlir (41 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/kernel-02-fused-softmax.mlir (42 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/ridiculously_nested_loops.mlir (43 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/early_return.mlir (44 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_argmin_argmax_2d.mlir (45 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/kernel-05-layer-norm-dwdb.mlir (46 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/block_ptr_advance.mlir (47 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/unsupported_extern_elementwise.mlir (48 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/masked_ldst_1d.mlir (49 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/kernel-05-layer-norm-fwd.mlir (50 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/kernel-01-vector-add.mlir (51 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/kernel-03-matrix-multiplication.mlir (52 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducesum_512_256_bf16_axis1.mlir (53 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_for_accumulation.mlir (54 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/cumsum.mlir (55 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/kernel-05-layer-norm-dwdb.mlir (56 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_for_expand_ptr.mlir (57 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/masked_ldst_sitofp_other.mlir (58 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reduce_extend_fp32_precision.mlir (59 of 216)
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir (60 of 216)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :38:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save0, %5 : tensor<128x128x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :38:5: note: see current operation: tt.store %arg3, %19 : tensor<128x128x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :38:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save0, %5 : tensor<128x128x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :38:5: note: see current operation: tt.store %arg3, %19 : tensor<128x128x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :39:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save1, %6 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :39:5: note: see current operation: tt.store %arg4, %20 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :39:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save1, %6 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :39:5: note: see current operation: tt.store %arg4, %20 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :40:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save2, %7 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :40:5: note: see current operation: tt.store %arg5, %21 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :40:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save2, %7 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :40:5: note: see current operation: tt.store %arg5, %21 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :41:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save3, %10 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :41:5: note: see current operation: tt.store %arg6, %22 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :41:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save3, %10 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :41:5: note: see current operation: tt.store %arg6, %22 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :42:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save4, %11 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :42:5: note: see current operation: tt.store %arg7, %23 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :42:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save4, %11 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :42:5: note: see current operation: tt.store %arg7, %23 : tensor<128x128x!tt.ptr<f32>>
tensor<128x128x!tt.ptr<bf16>>
tensor<128x128x!tt.ptr<f32>>
tensor<128x128x!tt.ptr<f32>>
tensor<128x128x!tt.ptr<f32>>
tensor<128x128x!tt.ptr<f32>>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, !tt.ptr<i32>, !tt.ptr<f16>, tensor<128x128x!tt.ptr<bf16>>, tensor<128x128x!tt.ptr<f32>>, tensor<128x128x!tt.ptr<f32>>, tensor<128x128x!tt.ptr<f32>>, tensor<128x128x!tt.ptr<f32>>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<i32>, %arg2: !tt.ptr<f16>, %arg3: tensor<128x128x!tt.ptr<bf16>>, %arg4: tensor<128x128x!tt.ptr<f32>>, %arg5: tensor<128x128x!tt.ptr<f32>>, %arg6: tensor<128x128x!tt.ptr<f32>>, %arg7: tensor<128x128x!tt.ptr<f32>>):
    %0 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
    %1 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
    %2 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
    %3 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
    %4 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
    %5 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %7 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %8 = "tts.make_tptr"(%arg0) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: 0, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>) -> tensor<128x128x!tt.ptr<f32>>
    %9 = "tts.make_tptr"(%arg1) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: 0, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<i32>) -> tensor<128x128x!tt.ptr<i32>>
    %10 = "tts.make_tptr"(%arg2) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: 0, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f16>) -> tensor<128x128x!tt.ptr<f16>>
    %11 = "tts.load"(%8) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %12 = "tts.load"(%9) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<i32>>) -> tensor<128x128xi32>
    %13 = "tts.load"(%10) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f16>>) -> tensor<128x128xf16>
    %14 = "arith.truncf"(%11) : (tensor<128x128xf32>) -> tensor<128x128xbf16>
    %15 = "math.exp"(%11) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>) -> tensor<128x128xf32>
    %16 = "arith.sitofp"(%12) : (tensor<128x128xi32>) -> tensor<128x128xf32>
    %17 = "arith.extf"(%13) : (tensor<128x128xf16>) -> tensor<128x128xf32>
    %18 = "math.sqrt"(%11) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>) -> tensor<128x128xf32>
    "tt.store"(%4, %14) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xbf16>) -> ()
    "tt.store"(%3, %15) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
    "tt.store"(%2, %16) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
    "tt.store"(%1, %17) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
    "tt.store"(%0, %18) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
processing val
%7 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
actual processing
~~~~
processing val
%6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
actual processing
~~~~
processing val
%5 = "arith.constant"() <{value = 0 : i32}> : () -> i32
these are the uses:
actual processing
~~~~
processing val
%4 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
these are the uses:
"tt.store"(%4, %14) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xbf16>) -> ()
actual processing
processing user
"tt.store"(%4, %14) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xbf16>) -> ()
tensor<128x128x!tt.ptr<bf16>>
~~~~
processing val
%3 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
these are the uses:
"tt.store"(%3, %15) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
actual processing
processing user
"tt.store"(%3, %15) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
tensor<128x128x!tt.ptr<f32>>
~~~~
processing val
%2 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
these are the uses:
"tt.store"(%2, %16) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
actual processing
processing user
"tt.store"(%2, %16) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
tensor<128x128x!tt.ptr<f32>>
~~~~
processing val
%1 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
these are the uses:
"tt.store"(%1, %17) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
actual processing
processing user
"tt.store"(%1, %17) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
tensor<128x128x!tt.ptr<f32>>
~~~~
processing val
%0 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
these are the uses:
"tt.store"(%0, %18) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
actual processing
processing user
"tt.store"(%0, %18) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
tensor<128x128x!tt.ptr<f32>>
~~~~
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, !tt.ptr<i32>, !tt.ptr<f16>, tensor<128x128x!tt.ptr<bf16>>, tensor<128x128x!tt.ptr<f32>>, tensor<128x128x!tt.ptr<f32>>, tensor<128x128x!tt.ptr<f32>>, tensor<128x128x!tt.ptr<f32>>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<i32>, %arg2: !tt.ptr<f16>, %arg3: tensor<128x128x!tt.ptr<bf16>>, %arg4: tensor<128x128x!tt.ptr<f32>>, %arg5: tensor<128x128x!tt.ptr<f32>>, %arg6: tensor<128x128x!tt.ptr<f32>>, %arg7: tensor<128x128x!tt.ptr<f32>>):
    %0 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
    %1 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
    %2 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
    %3 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
    %4 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
    %5 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %7 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %8 = "tts.make_tptr"(%arg0) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: 0, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>) -> tensor<128x128x!tt.ptr<f32>>
    %9 = "tts.make_tptr"(%arg1) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: 0, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<i32>) -> tensor<128x128x!tt.ptr<i32>>
    %10 = "tts.make_tptr"(%arg2) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: 0, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f16>) -> tensor<128x128x!tt.ptr<f16>>
    %11 = "tts.load"(%8) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %12 = "tts.load"(%9) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<i32>>) -> tensor<128x128xi32>
    %13 = "tts.load"(%10) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f16>>) -> tensor<128x128xf16>
    %14 = "arith.truncf"(%11) : (tensor<128x128xf32>) -> tensor<128x128xbf16>
    %15 = "math.exp"(%11) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>) -> tensor<128x128xf32>
    %16 = "arith.sitofp"(%12) : (tensor<128x128xi32>) -> tensor<128x128xf32>
    %17 = "arith.extf"(%13) : (tensor<128x128xf16>) -> tensor<128x128xf32>
    %18 = "math.sqrt"(%11) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>) -> tensor<128x128xf32>
    %19 = "tts.create_ptr"(%arg3, %4) : (tensor<128x128x!tt.ptr<bf16>>, tensor<128x128xi32>) -> tensor<128x128x!tt.ptr<bf16>>
    "tt.store"(%4, %14) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xbf16>) -> ()
    %20 = "tts.create_ptr"(%arg4, %3) : (tensor<128x128x!tt.ptr<f32>>, tensor<128x128xi32>) -> tensor<128x128x!tt.ptr<f32>>
    "tt.store"(%3, %15) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
    %21 = "tts.create_ptr"(%arg5, %2) : (tensor<128x128x!tt.ptr<f32>>, tensor<128x128xi32>) -> tensor<128x128x!tt.ptr<f32>>
    "tt.store"(%2, %16) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
    %22 = "tts.create_ptr"(%arg6, %1) : (tensor<128x128x!tt.ptr<f32>>, tensor<128x128xi32>) -> tensor<128x128x!tt.ptr<f32>>
    "tt.store"(%1, %17) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
    %23 = "tts.create_ptr"(%arg7, %0) : (tensor<128x128x!tt.ptr<f32>>, tensor<128x128xi32>) -> tensor<128x128x!tt.ptr<f32>>
    "tt.store"(%0, %18) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
total addptr count: 0
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:49:16: error: CHECK-SAME: expected string not found in input
// CHECK-SAME: ([[PARAM_0_:%.+]]: memref<*xf32>, [[PARAM_1_:%.+]]: memref<*xi32>, [[PARAM_2_:%.+]]: memref<*xf16>, [[PARAM_3_:%.+]]: tensor<128x128x!tt.ptr<bf16>>, [[PARAM_4_:%.+]]: tensor<128x128x!tt.ptr<f32>>, [[PARAM_5_:%.+]]: tensor<128x128x!tt.ptr<f32>>, [[PARAM_6_:%.+]]: tensor<128x128x!tt.ptr<f32>>, [[PARAM_7_:%.+]]: tensor<128x128x!tt.ptr<f32>>, [[PARAM_8_:%.+]]: i32, [[PARAM_9_:%.+]]: i32, [[PARAM_10_:%.+]]: i32, [[PARAM_11_:%.+]]: i32, [[PARAM_12_:%.+]]: i32, [[PARAM_13_:%.+]]: i32) {
               ^
<stdin>:3:19: note: scanning from here
 func.func @kernel(%arg0: memref<*xf32>, %arg1: memref<*xi32>, %arg2: memref<*xf16>, %arg3: memref<128x128xbf16>, %arg4: memref<128x128xf32>, %arg5: memref<128x128xf32>, %arg6: memref<128x128xf32>, %arg7: memref<128x128xf32>, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32) {
                  ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
         1: #map = affine_map<(d0, d1) -> (d0, d1)> 
         2: module { 
         3:  func.func @kernel(%arg0: memref<*xf32>, %arg1: memref<*xi32>, %arg2: memref<*xf16>, %arg3: memref<128x128xbf16>, %arg4: memref<128x128xf32>, %arg5: memref<128x128xf32>, %arg6: memref<128x128xf32>, %arg7: memref<128x128xf32>, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32) { 
same:49                       X~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ error: no match found
         4:  %c0 = arith.constant 0 : index 
same:49     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         5:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [128, 128], strides: [1, 1] : memref<*xf32> to memref<128x128xf32, strided<[1, 1]>> 
same:49     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         6:  %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [0], sizes: [128, 128], strides: [1, 1] : memref<*xi32> to memref<128x128xi32, strided<[1, 1]>> 
same:49     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         7:  %reinterpret_cast_1 = memref.reinterpret_cast %arg2 to offset: [0], sizes: [128, 128], strides: [1, 1] : memref<*xf16> to memref<128x128xf16, strided<[1, 1]>> 
same:49     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         8:  %alloc = memref.alloc() : memref<128x128xf32> 
same:49     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         .
         .
         .
>>>>>>

--

********************
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_512_256_bf16_axis1.mlir (61 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/bitcast.mlir (62 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/convert_argmin_argmax.mlir (63 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/tensor_indices_loop_iterargs_not_used_ptranalysis_prepass.mlir (64 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_nested.mlir (65 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_512_256_f32_axis0.mlir (66 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/tensor_indices_loop_iterargs_nested.mlir (67 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/use_end_chain.mlir (68 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_nested.mlir (69 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_tensor_reshape.mlir (70 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_nested.mlir (71 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/wraparound_side_by_side.mlir (72 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_1d_elemwise_arith_unary.mlir (73 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/kernel-02-fused-softmax.mlir (74 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/arith_not_ptr_arith.mlir (75 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/get_num_programs.mlir (76 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/triton_assert.mlir (77 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_addi_reduce.mlir (78 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/early_return.mlir (79 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_1d_elemwise_arith_binary.mlir (80 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_1d_elemwise_arith_ternary.mlir (81 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/arith_not_ptr_arith.mlir (82 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_2d_elemwise_arith_ternary.mlir (83 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_minmax_reduce.mlir (84 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/wraparound_unsupported_add_offset.mlir (85 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/masked_ldst_2d.mlir (86 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/wraparound_stacked.mlir (87 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_dim1.mlir (88 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_mul_const_const.mlir (89 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/masked_ldst_1d.mlir (90 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducesum_middle_dim.mlir (91 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_mul_value_const.mlir (92 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/make_tensor_ptr_ordering_error.mlir (93 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/use_dot_opc.mlir (94 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_for_used_after_update.mlir (95 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/masked_ldst_2d.mlir (96 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_for_used_before_update.mlir (97 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_512_256_f32_axis1.mlir (98 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducesum_scalar.mlir (99 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_for_accumulation.mlir (100 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/masked_ldst_sitofp_other.mlir (101 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducesum_512_256_f32_axis1.mlir (102 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_argmin_argmax.mlir (103 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/kernel-05-layer-norm-fwd.mlir (104 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_512_256_bf16_axis0.mlir (105 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/use_dot_opc.mlir (106 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/kernel-03-matrix-multiplication.mlir (107 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_splat.mlir (108 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_2d_elemwise_arith_unary.mlir (109 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/convert_tensor_reshape.mlir (110 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/use_mid_chain.mlir (111 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_nested.mlir (112 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_minmax_reduce.mlir (113 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_minmax_fp_reduce.mlir (114 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_for_more_init_args.mlir (115 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_add_value.mlir (116 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/cumsum.mlir (117 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/wraparound_stacked.mlir (118 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_for_used_before_update.mlir (119 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_minmax_fp_reduce.mlir (120 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/bitcast.mlir (121 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducesum_512_256_bf16_axis0.mlir (122 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_2d_elemwise_arith_unary.mlir (123 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/wraparound_side_by_side.mlir (124 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/convert_extern_elementwise.mlir (125 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_dim1.mlir (126 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_splat.mlir (127 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/bitcast.mlir (128 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/kernel-05-layer-norm-dwdb.mlir (129 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducesum_middle_dim.mlir (130 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_reshape_broadcast.mlir (131 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_for_more_init_args.mlir (132 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_nested.mlir (133 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducesum_512_256_f32_axis1.mlir (134 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_1d_elemwise_arith_ternary.mlir (135 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/use_end_chain.mlir (136 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/block_ptr_advance.mlir (137 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/kernel-01-vector-add.mlir (138 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_mul_value_const.mlir (139 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_for_more_init_args.mlir (140 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_addi_reduce.mlir (141 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/tensor_indices_loop_iterargs_not_used_ptranalysis_e2e.mlir (142 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_2d_elemwise_arith_ternary.mlir (143 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_broadcast.mlir (144 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_2d_example.mlir (145 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_2d_example.mlir (146 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_for_2d.mlir (147 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/tensor_indices_loop_iterargs_nested.mlir (148 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_1d_elemwise_arith_unary.mlir (149 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_2d_elemwise_arith_binary.mlir (150 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducemax_32_256_bf16.mlir (151 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/wraparound_side_by_side.mlir (152 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducesum_scalar.mlir (153 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/arith_not_ptr_arith.mlir (154 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/tensor_indices_loop_iterarg_with_masks.mlir (155 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_splat_float.mlir (156 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/use_mid_chain.mlir (157 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_for_used_after_update.mlir (158 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_argmin_argmax_2d.mlir (159 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_reshape_broadcast.mlir (160 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_add_value.mlir (161 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/bitcast.mlir (162 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_loopback.mlir (163 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/masked_ldst_sitofp_other.mlir (164 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/kernel-01-vector-add.mlir (165 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/get_num_programs.mlir (166 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_1d_elemwise_arith_binary.mlir (167 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/use_mid_chain.mlir (168 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_mul_const_const.mlir (169 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_splat_2d.mlir (170 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/dot.mlir (171 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_for_2d.mlir (172 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_for_expand_ptr.mlir (173 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducesum_512_256_f32_axis0.mlir (174 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_for_used_after_update.mlir (175 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducesum_512_256_bf16_axis0.mlir (176 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/sign_extend_i32_to_i64.mlir (177 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_2d_example.mlir (178 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/dot.mlir (179 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_splat_2d.mlir (180 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_2d_elemwise_arith_binary.mlir (181 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducemax_32_256_bf16.mlir (182 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducesum_512_256_bf16_axis1.mlir (183 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/use_end_chain.mlir (184 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/use_dot_opc.mlir (185 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_loopback.mlir (186 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_for.mlir (187 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_mul_const_const.mlir (188 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_minmax.mlir (189 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_splat.mlir (190 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_splat_float.mlir (191 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_broadcast.mlir (192 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/cumsum.mlir (193 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_nested.mlir (194 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_add_value.mlir (195 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducesum_512_256_f32_axis0.mlir (196 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_loopback.mlir (197 of 216)
XFAIL: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_dim1.mlir (198 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/kernel-02-fused-softmax.mlir (199 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_for_used_before_update.mlir (200 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_mul_value_const.mlir (201 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/triton_assert.mlir (202 of 216)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/triton_assert.mlir (203 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/masked_ldst_2d.mlir (204 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/unsupported_extern_elementwise.mlir (205 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_for_expand_ptr.mlir (206 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_argmin_argmax.mlir (207 of 216)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/unsupported_extern_elementwise.mlir (208 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/masked_ldst_1d.mlir (209 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_for.mlir (210 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_loopback.mlir (211 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_tensor_reshape.mlir (212 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_reshape_broadcast.mlir (213 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/block_ptr_advance.mlir (214 of 216)
XFAIL: TRITON-SHARED :: Conversion/TritonToLinalg/wraparound_unsupported_add_offset.mlir (215 of 216)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_broadcast.mlir (216 of 216)
********************
Unresolved Tests (1):
  TRITON-SHARED :: Conversion/fail.mlir

********************
Failed Tests (23):
  TRITON-SHARED :: Conversion/StructuredToMemref/addptr_chain.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_for.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_loopback.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/block_ptr_complex_offset.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_addi_reduce.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax_reduce.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_splat_float.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_middle_dim.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_scalar.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_loop.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_nested_loop.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir


Testing Time: 1.21s

Total Discovered Tests: 216
  Passed           : 189 (87.50%)
  Expectedly Failed:   3 (1.39%)
  Unresolved       :   1 (0.46%)
  Failed           :  23 (10.65%)
